# 第五章。管理文件系统

在本章中，我们将涵盖以下主题:

*   创建虚拟块设备
*   格式化和挂载文件系统
*   使用磁盘配额
*   维护文件系统
*   扩展文件系统的容量

# 简介

本章是一个食谱的集合，提供了驱动基于 CentOS 的服务器解决方案的需求。从格式化和装载磁盘到扩展逻辑卷以及维护文件系统和磁盘配额，本章的目的是向您展示，在当今要求最苛刻的环境中，如何快速、轻松地处理管理用户需求的任务。

# 创建虚拟块设备

在本食谱中，我们将创建一个虚拟块设备，我们将使用它来模拟真实的设备和分区，以便我们可以测试本章后面所有食谱中使用的驱动概念和命令。使用真实磁盘和分区通常会有丢失重要数据甚至不得不重新安装整个系统的风险。虚拟块设备是在切换到“生产模式”之前学习技术和尝试的理想选择。后来，如果你获得了足够的经验并感到安全，你可以很容易地用“真实”的硬件设备、分区和逻辑卷(这是 LVM 的一部分；见后面的食谱)。您所需要做的就是用“真实”的块设备名称替换您的虚拟设备。

## 做好准备

要完成此方法，您将需要最低限度地安装具有根访问权限的 CentOS 7 操作系统。要创建虚拟块设备，您应该至少有 1gb 的可用硬盘空间，我们将暂时使用这些空间来创建和制作。您可以稍后删除这个预留空间(或者在重启时自动删除)。只是为了测试。

## 怎么做...

1.  首先，以`root`身份登录，创建一个大小为 1 千兆字节的空文件:

    ```
    dd if=/dev/zero of=/tmp/test-image.dd bs=1M count=1000

    ```

2.  现在，让我们从刚刚创建的文件中创建一个循环设备:

    ```
    losetup -fP  /tmp/test-image.dd

    ```

3.  接下来，打印生成的循环设备名称:

    ```
    losetup -a

    ```

4.  由于这将是当前系统中创建的第一个环路设备，输出如下所示(如果您之前创建了环路设备，`loop0`可以是不同的数字):

    ```
    /dev/loop0: [0035]:3714186 (/tmp/test-image.dd)

    ```

5.  要获得当前连接到系统的所有块设备的列表以及重要细节，请键入以下内容:

    ```
    lsblk -io NAME,TYPE,SIZE,MOUNTPOINT,FSTYPE,MODEL

    ```

6.  现在，让我们在新的循环设备上创建一个类型为`gpt`的新分区表(确认删除任何数据):

    ```
    parted /dev/loop0 mklabel gpt

    ```

7.  最后，从循环设备创建设备映射，使其更类似于真实硬盘分区:

    ```
    kpartx -a /dev/loop0

    ```

## 它是如何工作的...

在本菜谱中，我们学习了如何创建虚拟数据块设备，该设备将作为在本章后面的菜谱中测试如何创建分区、逻辑卷和文件系统的起点。

那么，我们从这次经历中学到了什么？

我们通过使用`dd`实用程序在`/tmp`目录中创建新的空文件来开始这个食谱，该文件大小为 1 千兆字节。`dd`用于制作文件的精确副本(有时称为克隆)，需要两个参数:一个输入文件(T3)参数和一个输出文件(T4)参数。我们使用`zero`设备(`/dev/zero`)作为我们的输入文件，该文件返回包含零的无尽字节流。然后，我们通过定义块大小(`bs`)和`count`参数来限制流。`bs`定义一次读取的字节数据量，而`count`参数计算`bs`允许重复多少次。因此，这些参数可以理解为*当我们达到块大小乘以接收的计数数据时*停止复制过程。在我们的例子中，我们使用的块大小为`1` *兆字节乘以 1000 = 1 千兆字节*。这个零字节数据被写入我们的输出文件(`of`)称为`/tmp/test-image.dd`。

在我们创建了这个空文件之后，我们用它创建了一个临时的**循环**设备。循环设备只是一个伪设备，可以将文件用作 **块设备**。通常，这样的文件是光盘 ISO 映像，将其用作循环设备将使其可访问，就像它是普通的硬件驱动器一样。任何允许在块中读取或写入数据的设备都可以称为块设备；为了获得系统中所有可用块设备的列表，我们使用了`lsblk`命令，如您所见，这也包括我们的环路设备。标准环路设备名称以数字零开始，如`/dev/loop0`所示。

之后，我们使用`parted`命令在我们的循环设备上创建了一个新的 **分区表**。分区表是操作系统在磁盘上维护的描述其上分区的表，在我们创建它们之前必须创建它。我们使用了分区表类型`gpt`，但是您也可以在这里使用旧的 msdos 类型来代替。

通常，在虚拟块设备上创建分区表时，我们不能访问单个分区，也不能为其上的不同分区创建文件系统，因为分区不能单独寻址。这里我们使用`kpartx`命令从分区表创建设备映射，这允许我们稍后使用循环设备 0 上的分区 1 的符号`/dev/loop0p1`和循环设备 0 上的分区 2 的符号`/dev/loop0p2`来访问单个分区以创建文件系统。

恭喜您，您现在已经创建了一个全新的虚拟块设备，它具有标准分区表，可以像普通磁盘设备一样使用和访问。

## 还有更多...

如果我们想要删除虚拟数据块设备，我们首先必须从文件系统中卸载它(如果它当前已装载)(例如，`umount /dev/loo0p1`)。接下来，我们需要使用像这样的`-d`参数从循环设备中分离虚拟块设备文件:`losetup -d /dev/loop0`。之后，我们可以删除块文件，如果我们想:`rm /tmp/test-image.dd`。

# 格式化和挂载文件系统

在本食谱中，您将被介绍到标准的 CentOS 文件系统**【XFS】****Ext4**和 **Btrfs** 。文件系统是任何操作系统最基本的部分之一，几乎所有的东西都依赖于它们。在这里，您将学习如何创建 CentOS 7 中可用的不同类型的标准文件系统，以及如何将它们链接到您的系统，以便我们以后可以访问它们进行读写。这两种技术称为 **格式化**和**挂载**文件系统；虽然你做并不经常这样做，但它仍然是 Linux 系统管理员最基本的任务之一。

## 做好准备

要完成此方法，您将需要最低限度地安装具有根访问权限的 CentOS 7 操作系统。我们还将使用虚拟块设备而不是真实的磁盘设备，因为最好演示使用“虚拟”设备创建文件系统和格式化磁盘的用法，而不是擦除真实的硬盘内容。因此，您应该已经应用了*创建虚拟块设备*的方法，并创建了一个 1gb 的虚拟块设备，在本例中将被命名为`/dev/loop0`。

如果你想把这个方法应用到真正的磁盘设备上，你所要做的就是用你正确的分区替换`/dev/loop0`——比如逻辑卷(LV)`/dev/mapper/myServer/data`，SATA 设备`/dev/sdX`，或者基于 IDE 的硬盘名称`/dev/hdX`(其中`X`是一个字符`a-z`)。

## 怎么做...

在我们的示例中，该块设备标记为`/dev/loop0`。请注意，如果您创建了多个数据块设备，您的编号可能会有所不同，因此请相应地更改名称:

1.  首先，让我们以`root`身份登录，并显示所有当前可用块设备的信息:

    ```
    lsblk -io NAME,TYPE,SIZE,MOUNTPOINT,FSTYPE,MODEL

    ```

2.  现在，重新检查设备上是否安装了有效的分区表:

    ```
    parted /dev/loop0 print

    ```

3.  前一行应打印出以下内容:`Partition Table: gpt`。如果不是这样，让我们创建一个新的分区表(确认删除任何数据):

    ```
    parted /dev/loop0 mklabel gpt

    ```

4.  现在，我们将创建一个跨越整个磁盘空间的新分区，带有一个`ext4`文件系统标签(还没有安装文件系统；只是一个标签):

    ```
    parted -a optimal /dev/loop0 mkpart primary ext4 2048KiB 100%

    ```

5.  再次打印分区表，显示我们刚刚创建的新分区:

    ```
    parted /dev/loop0 print

    ```

6.  现在，让我们移除分区:

    ```
    parted /dev/loop0 rm 1

    ```

7.  我们还可以创建一个 btrfs 标记的分区:

    ```
    parted -a optimal /dev/loop0 unit MB mkpart primary btrfs 2048KiB 100%

    ```

8.  然后，让我们创建一个跨越整个磁盘的 XFS 标记的分区:

    ```
    parted /dev/loop0 rm 1
    parted -a optimal /dev/loop0 mkpart primary xfs 2048KiB 100%

    ```

9.  现在，再次显示块表，看看我们改变了什么:

    ```
    lsblk -io NAME,TYPE,SIZE,MOUNTPOINT,FSTYPE,MODEL

    ```

10.  因为我们只有定义了分区类型*标签*，所以我们的分区上仍然没有有效的文件系统；因此，在下一步中，我们使用正确的类型格式化磁盘。我们以 XFS 为例。如果使用`ext4`或`btrfs`代替

    ```
    mkfs -t xfs /dev/loop0p1

    ```

    ，请更改`mkfs -t <type>`
11.  接下来，让我们在系统上安装我们的虚拟块设备分区，进入目录`/media/vbd-1`，如果您使用`ext4`或`btrfs`来代替:

    ```
    mkdir /media/vbd-1
    mount -t xfs /dev/loop0p1  /media/vbd-1

    ```

    ，请更改`-t <type>`
12.  最后，测试我们是否可以读写新的文件系统:

    ```
    echo "this is a test" > /media/vbd-1/testfile.txt
    cat /media/vbd-1/testfile.txt

    ```

## 它是如何工作的…

在这个食谱中，我们向用户展示了如何创建横跨整个磁盘的 CentOS 7 标准分区，然后我们在这些分区上创建了一些文件系统，这被称为格式化，使用不同的文件系统类型。CentOS 7 中可用的标准文件系统是 XFS，但正如我们在本食谱中了解到的，还有许多其他可用的文件系统，包括流行的 ext4 和 btrfs。XFS 是一个非常健壮和高性能的文件系统，适用于大型存储配置；它被认为非常成熟和稳定。在 CentOS 7 之前，标准文件系统是 ext4，但是它有一些限制，并且在处理数百万个文件时性能不是最好的，被认为几乎不适合当今非常大的文件系统。btrfs 是一个相对较新的文件系统，包含在 CentOS 7 中，但在撰写本文时，它仍在开发中，不应用于生产系统。在后来的 CentOS 7 小版本中，它被认为是完全受支持的，并且有可能在未来取代 XFS 成为标准的 CentOS 文件系统类型，因为它有一系列非常有前途的特性和增强功能，例如写入时复制，每次写入文件时都会复制文件，并且可以恢复到以前的文件版本。

那么我们从这次经历中学到了什么？

我们通过使用`lsblk`命令打印当前连接到系统的所有可用块设备的列表来启动此配方。我们使用这个命令来检查我们想要用来安装分区和文件系统的目标块设备是否可用。在我们的示例中，我们将使用`/dev/loop0`设备，如果您的系统不同，请更改此名称(如前所述，您也可以使用“真实”的磁盘块设备，如`/dev/sda`，但一定要小心！).确认设备准备就绪后，我们使用`parted`命令检查磁盘的分区表。任何硬盘都必须有分区表来记录其上的分区信息。如您所见，我们创建分区表和分区的主要工具是 *parted* ，因为它是官方推荐的用于这些任务的 CentOS 7 工具，但也有其他程序也是这样做的，例如`fdisk`或`gdisk`。如果没有可用的分区表，我们必须使用 parted 的`mklabel gpt`参数创建一个类型`gpt`。

接下来，在创建分区表之后，我们在其上放置一些分区。因此，我们用`-a optimal primary ext4 2048KiB 100%` 选项发出了 parted 的`mkpart`命令。

### 注

始终小心`parted`命令，在执行前重新检查所有内容，因为它的大多数命令会完全销毁当前存储在磁盘上的所有数据。

这将创建一个新的分区，从 2，048 千字节(kb)开始，直到磁盘结束。我们没有从磁盘的最开始(0%)开始，因为 2，048 kb 是磁盘上第一个扇区的开始，留下一些空间来存储一些额外的数据。`-a optimal`将分区与保证最佳性能的物理块大小的倍数对齐。接下来，我们使用`rm`选项和编号`1`再次移除分区，这是指我们刚刚创建的第一个分区。我们重新创建了类型为`btrfs`的新分区，最后是`xfs`。磁盘分区后，我们需要一个实际的文件系统，因为 parted 只是将分区标记为特定的类型，而不进行实际的格式化。为了创建文件系统，我们使用`mkfs`实用程序。您可以像我们一样使用`-t`标志运行它，或者使用点符号，如`mkfs.xfs`，来指定您想要格式化的类型。`mkfs`命令给出了它所做工作的详细输出，比如写了多少块等等。

最后，在我们的磁盘分区上创建了文件系统之后，我们可以使用`mount`命令使其可用，并在当前系统中使用它。`mount`将设备的文件系统连接或分离到我们系统的根文件系统。因此，我们需要首先创建一个目录来定义我们想要将其附加到的位置。我们使用目录`/media/vbd-1`作为实际`mount`命令的参数，语法为`mount -t <file system type> <device> <dir>`。对于几乎所有标准文件系统，您可以跳过`-t`参数，因为它将自动检测正确的类型。要从系统中分离文件系统，您可以使用`umount`命令和您想要删除的设备的参数(您也可以使用它装载到的文件夹；两者都有效！).在我们的示例中，要卸载环路设备的第一个分区，请键入`umount /dev/loop0p1`。

安装好格式化的分区设备后，我们可以像根文件夹下的任何其他组件一样访问它。

## 还有更多...

在这个方法中，我们总是使用一个分区来跨越整个可用磁盘空间。通常，一个磁盘上有多个分区，所以让我们创建这种布局。在本例中，我们在`/dev/loop0`上创建了三个 100 MB 的分区:

1.  首先，让我们再次使用`rm`参数删除我们的分区，这样我们就可以添加新的分区:

    ```
    parted /dev/loop0 rm 1

    ```

2.  现在，让我们创建三个相等的分区:

    ```
    parted -a optimal /dev/loop0 unit MiB mkpart primary ext4 2048KiB 100
    parted -a optimal /dev/loop0 unit MiB mkpart primary ext4 100 200
    parted -a optimal /dev/loop0 unit MiB mkpart primary ext4 300 400

    ```

3.  Let's review our layout:

    ```
    parted /dev/loop0 print

    ```

    ### 注

    使用`gpt`分区表，我们可以在任意磁盘上创建多达 128 个主分区；使用较旧的`msdos`分区类型时，最多有四个主分区。如果您需要更多，您必须从主分区创建扩展分区。

# 使用磁盘配额

当管理一个有许多系统用户的 Linux 多用户系统时，对系统共享的资源设置某种限制是明智的。在文件系统级别，您可以在用户、组或目录级别将可用硬盘空间或总文件数限制为固定大小。这种规则的引入可以防止人们“滥发”系统，填满系统的可用空间，通常情况下，您的用户会更清楚重要数据和不重要数据之间的区别，并且更有可能保持他们的主目录整洁干净。在本食谱中，我们将向您展示如何为 XFS 文件系统设置**磁盘配额**限制系统，该系统限制您的系统用户帐户可以存储的数据量。

## 做好准备

要完成此方法，您将需要最低限度地安装具有根访问权限的 CentOS 7 操作系统和您选择的基于控制台的文本编辑器。要使该方法起作用，并且为了设置配额，您将需要根帐户旁边至少有一个系统用户帐户；如果您还没有，请参考[第 3 章](03.html#10DJ41-4cf34a6d07944734bb93fb0cd15cce8c "Chapter 3. Managing the System")*管理系统*中的食谱*管理用户及其群组*来学习如何创建一个。此外，在主食谱中，预计您的 CentOS 7 使用 XFS 文件系统，这是安装的标准。最后，您的 CentOS 7 安装需要安装在至少有 64 GB 空间的磁盘上，否则安装程序不会创建单独的*逻辑`/home`卷，这是本食谱中使配额工作所必需的。*

 *## 怎么做...

在这里，我们将学习如何以两种不同的方式为 XFS 文件系统设置配额系统:首先，对用户和组设置限制，然后在目录(项目)级别设置限制。必须在文件系统装载时设置磁盘配额系统。

### 启用用户和组配额

1.  首先，以`root`身份登录，打开`fstab`文件，其中包含静态挂载信息:

    ```
    vi /etc/fstab

    ```

2.  现在，将光标定位到包含`/home`的行(使用*向上*和*向下*箭头键)，并将其移动到单词`defaults`，然后在`defaults`后添加以下文本，用逗号分隔:

    ```
    ,uquota,gquota

    ```

3.  完整的行如下所示(您的设备名称会有所不同，具体取决于您个人的 LVM 名称；这里是`myserver` ):

    ```
    /dev/mapper/myserver-home /home  XFS    defaults,uquota,gquota 0 0

    ```

4.  保存并关闭文件，然后重新挂载`/home`分区激活`quota`指令:

    ```
    umount /home;mount -a

    ```

5.  接下来，为名为`john`的特定用户在总文件大小上创建用户配额(适当更改以匹配您系统上的可用用户:

    ```
    xfs_quota -x -c 'limit bsoft=768m bhard=1g john' /home/

    ```

6.  接下来，为另一个用户`joe`可以拥有的文件总量*创建一个用户配额:

    ```
    xfs_quota -x -c 'limit isoft=1000 ihard=5000 joe' /home/

    ```* 
7.  让我们为用户组`devgrp`(文件系统组`devgrp`必须存在)中的每个人创建文件数量和大小限制:

    ```
    xfs_quota -x -c 'limit -g bsoft=5g bhard=6g isoft=10000 ihard=50000 devgrp' /home

    ```

8.  最后，显示`home`卷的整个配额报告:

    ```
    xfs_quota -x -c 'report -bi -h' /home

    ```

### 启用项目(目录)配额

为了启用单个目录的磁盘配额，而不是用户或组配额，我们必须将名为`pquota`的项目配额指令添加到包含该目录的卷中。由于我们将使用名为`/srv/data`的目录作为我们的项目配额，我们需要在配额控制下获取完整的底层`/`根分区。对于根分区，我们必须将配额标志设置为内核引导选项:

1.  首先，在第一次备份后，以 root 用户身份打开以下文件:

    ```
    cp /etc/default/grub /etc/default/grub.BAK
    vi /etc/default/grub

    ```

2.  将`rootflags=pquota`指令添加到行尾(在它之前添加一个空白字符)，在结束双引号之前以`GRUB_CMDLINE_LINUX=`开始，如下所示:

    ```
    GRUB_CMDLINE_LINUX="rd.lvm.lv=centos/root rd.lvm.lv=centos/swap crashkernel=auto rhgb quiet rootflags=pquota"

    ```

3.  保存并关闭文件，然后用我们新的`boot`选项

    ```
    grub2-mkconfig -o /boot/grub2/grub.cfg

    ```

    重建`grub`配置
4.  现在，将`pquota`标记也添加到`/etc/fstab`的根卷中:

    ```
    vi /etc/fstab

    ```

5.  将光标定位到包含根挂载点/的行，并将其移动到单词`defaults`，然后添加以下文本，用逗号分隔:

    ```
    ,prjquota

    ```

6.  完整的线看起来类似如下:

    ```
    /dev/mapper/myserver-root /         XFS    defaults,prjquota 0 0

    ```

7.  接下来，重新启动计算机，将您的更改应用到`root`卷:

    ```
    reboot

    ```

8.  重新启动后，确保`root`卷已启用项目配额，这在卷的选项中定义为`prjquota`标志(否则，如果它是错误的并且不起作用，它将显示为`noquota` ):

    ```
    cat /etc/mtab  | grep root

    ```

9.  接下来，让我们创建我们想要为其设置配额的目标文件夹:

    ```
    mkdir /srv/data

    ```

10.  我们需要添加一个项目名称和一个相关的新的，唯一的 ID:

    ```
    echo "myProject:1400" >> /etc/projid

    ```

11.  现在，从我们的项目标识

    ```
    echo "1400:/srv/data" >> /etc/projects

    ```

    中定义`/srv/data`将使用配额规则
12.  接下来，初始化`root`卷的`project`配额:

    ```
    xfs_quota -xc 'project -s myProject' /

    ```

13.  最后，应用以下规则创建特定的目录限制:

    ```
    xfs_quota -x -c 'limit -p bsoft=1000m bhard=1200m myProject' /

    ```

14.  打印出本设备的配额规则:

    ```
    xfs_quota -x -c 'report -bi -h' /

    ```

## 它是如何工作的...

在本食谱中，您学习了在用户、组或目录(项目)级别设置配额系统有多容易。此外，您还了解到定义配额有两种基本方式:要么限制*总文件大小*(称为数据块)，要么限制*文件数量*(称为信息节点)。

那么，我们从这次经历中学到了什么？

我们从设置用户和组配额开始这个食谱。如您所见，通过向`/etc/fstab`文件中选择的分区添加相关指令，可以轻松启用配额系统。因此，我们通过打开这个文件并为 XFS 用户添加特殊配额关键字来开始这个食谱，并将配额分组到我们的`/home`分区。为了应用这些更改，我们必须使用`mount`命令重新挂载文件系统。由于配额系统已经成功启动，我们使用`xfs_quota -x -c`命令行在我们启用的文件系统`/home`上设置一些配额限制。`-x`启用专家模式，而`-c`允许我们在命令行上运行命令作为参数。当运行`xfs_quota`而没有`-c`选项时，您将获得一个交互式提示。首先，我们为用户设置一些用户限制，`john`和`joe`。为此，我们用数字定义了以下参数:`bsoft`、`bhard`、`isoft`、`ihard`。如您所见，文件大小(**块**)和文件数量(**索引节点**)都有软限制和硬限制。数据块配额可以在典型指标中给出，如千字节(`k`)、兆字节(`m`)和千兆字节(`g`)，而信息节点是一个数字。软限制是一个阈值，当超过该阈值时，会向命令行打印出一条警告消息，而硬限制将阻止用户在配额保护下向文件系统添加更多数据或文件。之后，我们设置了一个基于组的配额。如果使用`-g`标志，将为组而不是用户定义限制。根据允许用户拥有的文件数量或总文件大小，使用组规则可以非常有助于将用户分成不同的组。最后，我们为所有当前配额限制生成了一份报告。我们在那里使用的命令是`'report -bi -h'`，它生成已用文件空间(块为`-b`)和文件总量(索引节点为`-i`)的报告。`-h`指定我们希望输出以兆字节或千兆字节为单位是人类可读的。

为了测试配额是否有效，让我们为用户`jack`创建以下数据块和信息节点配额:

```
xfs_quota -x -c 'limit bhard=20m jack' /home/
xfs_quota -x -c 'limit ihard=1000 jack' /home/

```

以用户`jack` ( `su - jack`)身份登录，运行以下命令:

```
dd if=/dev/urandom of=~/test.dd bs=1M count=21

```

使用此命令，用户`john`将尝试创建一个 21 兆字节大小的文件，但是当开始写入第 20 兆字节时，将出现以下错误消息:

```
dd: error writing '/home/jack/test.dd': Disk quota exceeded

```

现在，删除`~/test.dd`文件，以便我们可以开始另一个测试。如果您超出了文件数量限制，也会发生同样的情况。通过尝试创建 2，000 个多个文件来测试以下配额限制，同时配额限制为 1，000 个；通过添加大量新文件来做到这一点:`for i in {1..2000}; do touch ~/test$i.txt; done`。这将导致以下错误消息:

```
touch: cannot touch '/home/jack/test1001.txt': Disk quota exceeded

```

要暂时关闭特定文件系统的用户和组配额检查，您可以作为`root`用户运行`xfs_quota -x -c 'off -u -g' /home/` ( `-u`代表用户，`-g`代表组)。这只是暂时的；要重新启用它，您需要重新挂载感兴趣的文件系统，这就是`umount /home;mount -a`。要删除特定配额规则，只需将其限制设置为零，例如:

```
xfs_quota -x -c 'limit bhard=0 john' /home

```

接下来，我们在*目录*上设置配额，而不是用户/组级别。这是只有 XFS 文件系统才具备的功能；所有其他文件系统只能在磁盘或分区级别设置配额。如果您不想为特权用户或组设置配额限制，则能够控制目录层次结构的磁盘使用是非常有用的。要激活目录配额，我们首先必须将其作为内核启动选项来启用，因为默认情况下，根卷被标记为`noquota`。此外，我们在根分区中添加了`/etc/fstab`中的`prjquota`指令以使其工作。如果您想了解更多内核引导选项，请阅读[第 1 章](01.html#E9OE1-4cf34a6d07944734bb93fb0cd15cce8c "Chapter 1. Installing CentOS")、*安装 CentOS* 中的引导加载程序配方。要为根分区设置文件系统标志，我们需要重新启动系统。这样做之后，我们通过查看`mtab`文件来确保引导选项已经成功设置，该文件列出了所有当前安装的文件系统。接下来，我们在`/etc/projid`文件中设置一个带有关联的唯一项目 ID 的项目名称(我们随机选择`1400`)。在下一步中，我们将这个新的项目标识(`1400`)应用到`/etc/projects`文件中名为`/srv/data`的目录中。该系统允许对许多不同的目录应用特定的项目配额规则。之后，我们使用`xfs_quota`命令的`project`选项初始化了根分区的项目配额，然后为此项目名称创建了`limit`配额规则。在相应项目 id 下的`/etc/projects`文件中定义的所有目录都受该规则的影响。这种类型的系统可用于细粒度多文件夹配额规则。对于每个目录，您可以设置一个新的项目名称或重用一个特定的名称，使这个系统非常灵活。

在本食谱中，我们为我们的项目名称`myProject`创建了 1200 兆字节的块大小硬限制。要测试此配额，请键入以下内容:

```
dd if=/dev/zero of=/srv/data/dd.img bs=1M count=1201

```

这应该会在写入 1200 兆字节后停止`dd`，出现以下命令行错误消息:

```
dd: error writing '/srv/data/dd.img': No space left on device

```

## 还有更多...

顾名思义，这个配方中显示的`xfs_quota`程序只适用于 XFS 文件系统。如果您想在用户或组级别为其他文件系统(如 ext4 或 btrfs)使用磁盘配额，您必须安装`quota`包(`yum install quota`)。在设定配额的工作方式与本食谱中显示的步骤相似；请阅读手册`man quota`开始。

# 维护文件系统

在本食谱中，我们将学习如何检查一致性，并可选地修复 CentOS 7 文件系统。文件系统不一致是罕见的事件，文件系统检查通常在引导时自动运行。但是，如果系统管理员认为文件系统有问题，他们也应该知道如何手动运行这样的测试。

## 做好准备

要完成此方法，您将需要具有 root 权限的 CentOS 7 操作系统的有效安装。我们将使用虚拟数据块设备而不是真实的磁盘设备，因为我们*无法对*挂载的*磁盘应用任何文件系统检查。因此，您应该已经应用了*格式化和挂载文件系统*的方法，并创建了一个 1gb 的虚拟块设备，它有两个总大小一半的分区:首先是一个带有 XFS 的分区，然后是另一个带有 ext4 文件系统的分区。在本例中，我们将使用名为`/dev/loop0`的虚拟块设备。*

如前所述，这些可以很容易地与真实的磁盘名称交换。

## 怎么做...

1.  首先，以`root`身份登录，显示当前连接到系统的块设备的信息:

    ```
    lsblk -io NAME,TYPE,SIZE,MOUNTPOINT,FSTYPE,MODEL

    ```

2.  在这里，你应该看到`loop0`设备上有两个分区:`/dev/loop0p1`和`/dev/loop0p2`。如果您看到它们当前已装载到系统中，请立即卸载它们:

    ```
    umount /dev/loop0p1
    umount /dev/loop0p2

    ```

3.  现在，让我们检查 XFS 文件系统，在我们的例子中是 loop0p1(适当地更改):

    ```
    xfs_repair -n /dev/loop0p1

    ```

4.  对于磁盘上的第二个分区 ext4，我们将使用以下行:

    ```
    fsck -f /dev/loop0p2

    ```

## 它是如何工作的...

在本食谱中，我们了解了在 XFS 或 ext4 文件系统上运行文件系统检查是多么容易。您在这里应该学到的最重要的一课是，在运行任何文件系统检查之前，您总是必须*卸载*您的磁盘分区！

那么，我们从这次经历中学到了什么？

由于我们无法在任何已挂载的设备上运行任何文件系统检查，如果您想要检查系统的磁盘和分区，通常您必须在 *rescue* 模式下运行此类检查，在该模式下，您的文件系统未被挂载(例如，您不能卸载根分区进行检查，因为系统一直需要它，而对于单独的主分区，这是可能的)。

对于 XFS 文件系统，我们使用`xfs_repair`工具，对于所有其他系统，我们将使用带有`-f`参数(强制)的`fsck`程序来检查我们的文件系统。

需要注意的是，我们总是需要运行`fsck`而不是具体的`fsck.<file system type>`(比如`fsck.ext4`、`fsck.btrfs`，因为它会自动为你检测到合适的工具。这是必要的，因为如果你在错误的文件系统上运行了错误的特定的`fsck.<file system type>`工具(比如说在 btrfs 文件系统上运行`fsck.ext4`，它会彻底摧毁它！

## 还有更多...

到目前为止，我们只向您展示了如何使用`xfs_repair`和`fsck`来*检查*文件系统。如果在 XFS 文件系统上“检查”运行期间出现一些错误，请运行`xfs_repair`而不要使用`-n`选项，例如，使用`xfs_repair /dev/loop0p1`。在非 XFS 分区(如 ext4)上，您可以使用`-a`选项(`a`用于自动修复)运行`fsck`，例如`fsck -a /dev/loop0p2`。对于`fsck`，如果你有很多错误，最好也使用`-y`，这样你就不必确认每个错误修复。

现在，让我们模拟一下，如果我们使用虚拟块设备(*在任何真实的磁盘分区上永远不要*这样做)得到一个损坏的 XFS 文件系统会发生什么！):

1.  首先，将`/dev/loop0p1`分区挂载到根文件系统:

    ```
    mkdir /media/vbd-1
    mount -t xfs /dev/loop0p1  /media/vbd-1

    ```

2.  接下来，在这个挂载的文件系统上创建大量文件，例如，`2000`文件:

    ```
    for i in {1..2000}; do dd if=/dev/urandom bs=16 count=1 of=/media/vbd-1/file$i; done

    ```

3.  现在，使用`dd` :

    ```
    umount /dev/loop0p1
    dd bs=512 count=10 seek=100 if=/dev/urandom of=/dev/loop0p1

    ```

    卸载设备并破坏文件系统
4.  现在，运行文件系统检查:

    ```
    xfs_repair -n /dev/loop0p1

    ```

5.  这很可能会向您显示损坏文件的列表；为了修复它，请使用下面的行:

    ```
    xfs_repair /dev/loop0p1

    ```

您也可以在 ext4 虚拟块设备上模拟这样的文件系统损坏，然后使用`fsck -ay /dev/loop0p2`修复它。

# 扩展文件系统的容量

CentOS 7 使用**逻辑卷管理器** ( **LVM** )来组织您的分区的结构和可用容量。这是一个非常动态和灵活的系统，可以随着时间的推移进行扩展或重新安排，这在当今要求最苛刻和不断变化的环境中至关重要。此刻大数据或云计算等流行语随处可见。由于大量数据一直在产生，存储需求和磁盘空间必须以同样稳定的速度增长。在本教程中，您将学习如何使用 LVM 系统，如何扩展物理驱动器，以及如何缩减和扩展文件系统的容量。

## 做好准备

要完成此方法，您将需要具有 root 权限的 CentOS 7 操作系统的有效安装。我们将使用虚拟块设备而不是真实的磁盘设备从头开始向您展示如何首先设置 LVM，然后如何使用它。请阅读*创建虚拟块设备*食谱，用 GPT 分区表创建三个 1gb 的虚拟块设备，在本例中标记为`/dev/loop0`、`/dev/loop1`和`/dev/loop2`。

同样，如果你准备好了，请随意使用真正的磁盘设备。

## 怎么做...

首先，我们将从创建一个类似于标准 CentOS 7 LVM 结构的 LVM 测试环境开始，该环境是在安装每个服务器系统期间设置的:

1.  首先，让我们以`root`身份登录，并显示我们的虚拟数据块设备信息:

    ```
    lsblk -io NAME,SIZE

    ```

2.  接下来，在三个虚拟数据块设备(没有文件系统标签)的每一个上创建跨越整个磁盘的新分区:

    ```
    parted -a optimal /dev/loop0 mkpart primary  2048KiB 100%
    parted -a optimal /dev/loop1 mkpart primary  2048KiB 100%
    parted -a optimal /dev/loop2 mkpart primary  2048KiB 100%

    ```

3.  现在，让我们在每个环路设备上创建 LVM *物理卷*(键入`yes`以移除`gpt`标签):

    ```
    pvcreate /dev/loop0p1
    pvcreate /dev/loop1p1
    pvcreate /dev/loop2p1

    ```

4.  接下来，显示关于我们的物理体积的信息:

    ```
    pvdisplay

    ```

5.  接下来，我们将在第一个物理卷上创建一个新的 LVM 卷组:

    ```
    vgcreate myVG1 /dev/loop0p1

    ```

6.  现在，显示创建的组的信息:

    ```
    vgdisplay myVG1

    ```

7.  然后，让我们在第一个卷组上创建一些逻辑卷，这些逻辑卷将在我们的 Linux 系统中被视为虚拟分区:

    ```
    lvcreate -L 10m  -n swap myVG1
    lvcreate -L 100m -n home myVG1
    lvcreate -L 400m -n root myVG1

    ```

8.  接下来，显示关于逻辑卷的信息:

    ```
    lvdisplay myVG1

    ```

9.  现在，显示我们的底层卷组还剩多少可用空间，如果您想扩展一些逻辑卷，这一点变得很重要(参见输出中的`Free PE / Size`部分):

    ```
    vgdisplay myVG1

    ```

10.  然后，让我们在这些新的逻辑卷上创建文件系统:

    ```
    mkswap /dev/myVG1/swap
    mkfs.xfs /dev/myVG1/home
    mkfs.xfs /dev/myVG1/root

    ```

11.  现在，我们已经创建了我们的测试 LVM 系统(它非常类似于真正的 CentOS LVM 标准布局，但尺寸较小)，让我们开始使用它。
12.  首先，让我们将当前大小为`400`兆字节(`M`)的`root`分区缩小`200`兆字节，然后，让我们将`home`分区增加`500`兆字节(确认可能的数据丢失):

    ```
    lvresize -L -200m /dev/myVG1/root
    lvresize -L +500m /dev/myVG1/home

    ```

13.  再次使用`vgdisplay myVG1`通过运行前面的命令查看卷组的可用空间如何变化(参见`Free PE / Size`)。
14.  Now, let's expand the XFS filesystem on the grown logical volume:

    ```
    mkdir /media/home-test;mount /dev/myVG1/home /media/home-test
    xfs_growfs /dev/myVG1/home

    ```

    ### 注

    不要使用`resize2fs`来增长 XFS 文件系统，这是非常重要的，因为它不兼容，并且会损坏它们。

15.  现在，假设一段时间后，您的数据再次增长，并且您需要主分区为 1.5 千兆字节(`G`，但底层卷组上只剩下 184.00 MiB。首先，我们需要将本食谱开头的两个准备好的物理卷添加到我们的卷组中:

    ```
    vgextend myVG1 /dev/loop1p1 /dev/loop2p1
    vgdisplay myVG1

    ```

16.  之后，我们的卷组中有足够的可用空间(参见`Free PE / Size`)来扩展我们的主逻辑卷(卷必须保持装载状态):

    ```
    lvresize -L +1500m /dev/myVG1/home
    xfs_growfs /dev/myVG1/home

    ```

## 它是如何工作的...

在这里，在这个食谱中，我们已经向您展示了如何使用 LVM 为 XFS 分区。开发它的目的是动态管理几个硬盘上的磁盘空间。您可以轻松地将许多物理硬盘合并在一起，使它们在系统中显示为单个虚拟硬盘。与使用普通的旧静态分区相比，这使它成为一个灵活且可扩展的系统。传统分区受限于它们所驻留的总磁盘容量，并且无法扩展，它们的静态分区布局也不容易改变。此外，我们还介绍了一些重要的 LVM 技术术语，它们为硬盘提供了不同的抽象层，本节将对此进行解释，以便理解其背后的概念:**物理** **卷** ( **pv** )、**卷** **组** ( **vg** )和**逻辑卷** ( **lv** )。

那么，我们从这次经历中学到了什么？

我们首先创建了三个每个 1gb 的虚拟块设备，然后在每个设备上创建一个跨越整个设备的分区。然后，我们使用`pvcreate`命令将这些单分区设备定义为物理卷(pv)。光伏是一个 LVM 术语，它定义了 LVM 世界的存储单元。它必须在分区、全驱动器或环路设备上定义。pv 只是周围分区中所有可用空间的抽象，因此我们可以在 LVM 的基础上使用它。接下来，我们使用`vgcreate`命令创建了一个卷组(vg)，在这里我们还必须定义一个我们选择的卷组名称，并将其中的第一个 pv 作为基本存储卷。如您所见，一个 vg 是至少一个 pv 的容器(我们稍后会添加更多 pv)。在 vg 中添加或删除 pv 是 LVM 系统整个可扩展性概念的核心。pv 不必都是相同的大小，随着时间的推移，可以通过添加几十个新的物理驱动器来增加您的 vg，这些物理驱动器都被定义为 pv。您的系统上可以有多个 vg，您可以通过您给它们的唯一名称来识别它们。因此，总而言之，要扩展 vg 的空间，您必须用物理驱动器创建 pv，然后再添加到其中。

最后，我们在 vg 上创建了逻辑卷(lv)，它可以像 vg 中的真实物理分区一样被看到和使用。在这里，我们使用`lvcreate`命令创建了三个 lv，通过这个命令我们需要定义我们想要放置目标 lv 的 vg 的名称(记住，您的系统上可以有多个 vg)，以及卷的大小，以及作为最后一个参数的名称。您可以将多个 LV 添加到一个 vg 中，并且不需要使用 vg 底层空闲空间中的全部分配空间。你可以非常灵活地使用它。最棒的是，你对卷的大小和布局的决定不必一直固定不变；你可以以后随时更换。这是一个非常动态的系统，可以扩展和收缩、删除和创建，而无需事先卸载卷。但是你必须记住，所有的 LV 都绑定到一个 vg，没有它或者在它的空间边界之外是不可能创建它们的。如果您需要在底层 vg 的边界上扩展 lv 的空间，您必须扩展 vg，如本食谱所示。

### 注

您可能已经看到，对于每个 LVM 术语，都有一个“显示”和“创建”命令，因此很容易记住:`pvdisplay`、`vgdisplay`、`lvdisplay`、`pvcreate`、`vgcreate`、`lvcreate`。

成功创建 lv 后，您可以像处理系统上的所有其他块设备分区一样处理它们。唯一的区别是它们位于特殊的设备文件夹中:`/dev/<vg name>/<lv name>`或`/dev/mapper/<vg name>/<lv name>`。例如，本例中创建的主卷名为`/dev/myVG1/home`。最后，为了将它们用作正常的挂载点，我们在它们上面创建了一些测试文件系统。

在本食谱的第二部分，我们向您展示了如何扩展我们的 vg 以及如何缩小和扩展我们的 lv 测试系统。

我们首先使用`vgdisplay myVG1`命令显示 vg 上的当前可用空间。在命令输出中，我们看到我们当前的卷组共有`996M` ( `VG Size`)，从我们的 LV(`swap`、`home`、`root`)分配的大小是`512M` ( `Alloc PE / Size`)，空闲大小是`484M` ( `Free PE /Size`)。接下来，我们使用`lvresize`命令来收缩和扩展逻辑卷的根目录和主目录。`-L`参数设置卷的新大小，使用`+`或`-`符号，该值被添加到逻辑卷的实际大小或从逻辑卷的实际大小中减去。没有它，这个值就被认为是绝对的。请记住，我们只能增加主分区，因为当前的卷布局没有占据整个 vg 的总空间。调整大小后，如果我们再次使用`vgdisplay`命令，我们会看到我们现在在 vg 中占据了更多的空间；其自由尺寸已由减小至`184M`。既然我们已经将`home`卷从`100M`扩展到了`500M`，我们也需要记住扩展它的 XFS 文件系统，因为扩展卷不会自动扩展它的文件系统。因此，当前卷的`400M`是未分配的，没有任何文件系统信息。我们使用了命令`xfs_growfs`，它将在不定义限制参数的情况下，为 XFS 文件系统使用完整的未分配区域。如果您想要调整任何其他文件系统类型的大小，例如 ext4，您可以使用`resize2fs`命令来代替。

最后，我们想将家庭音量增加`1.5G`，但我们的 vg 上只剩下`184M`来扩展。这就是 LVM 真正*闪耀*的地方，因为我们可以给它添加更多的物理卷(在现实世界中，你可以在你的服务器上安装新的硬盘，并把它们作为 pvs 使用)。我们向您展示了如何使用`vgextend`命令通过添加两个 1G 大小的 pvs 来扩展 vg 的容量。后来，我们使用`vgdisplay`看到我们的 vg 现在已经增长到 3G 的总尺寸，所以最后我们可以扩展我们的家庭 lv，因为它现在将适合它。作为最后一步，我们再次扩展了 XFS 文件系统，以填满整个 2G 家庭卷大小。

请始终记住，如果您将 vg 与几个物理硬盘一起使用，您的数据将分布在这些硬盘中。LVM 不是一个 RAID 系统，没有冗余，所以如果一个硬盘出现故障，你的整个 vg 也会出现故障，你的数据也会丢失！为了解决这个问题，一个建议的解决方案是为硬盘使用物理磁盘阵列系统，并在此基础上创建一个 LVM。*