# Git、配置管理和作为代码的基础设施

在本章中，我们将研究以下主题:

*   Git 是什么？
*   设置 Git 服务器
*   提交到我们的 Git 存储库
*   分支我们的 Git 存储库并提交更改
*   安装 Ansible
*   使用 Ansible 从角色安装 Java
*   用 Git 存储我们的可转换配置
*   探索 IaC 的选择

# 介绍

曾经有一段时间，系统管理员非常了解他们的服务器。他们可以告诉你每一个风扇噪音，每一声哔哔声的含义，以及当服务器变热时金属膨胀时的声音。

和硬件一样，软件几乎在系统管理员的脑海中被超自然地索引，他们可以一针见血地告诉你他们运行的是什么版本的 OpenSSL、Apache 或午夜指挥官。

这里面有一个很明显的问题:*被公交车撞到*的效果。

如果一个系统管理员不幸在某天早上被砍倒，他的随身听被扔在路边，旁边是他的游戏男孩颜色的碎片，那么服务器的所有知识都会在一瞬间丢失。关于服务器启动的奇怪方式的知识将永远消失，这意味着它必须在正确的时间拔掉键盘。

你不希望一个人对与服务器相关的所有事情都了如指掌——你希望有多个用户，更进一步，你希望它以一种不仅容易复制和修改，而且最好简单到连电脑都能理解的格式写下来。

在这一章中，我们将研究软件世界中三个相对接近的东西——一个版本控制系统，叫做 Git 配置管理的概念，多以 Ansible 的形式出现；和基础设施作为代码，具有每个人的最爱，地形和包装。

事实上，我们已经通过使用游民做了很多事情。虽然规模很小，但是 float 实际上是一种将基础设施作为代码的方法。我们放入到我们的两个游民文件中的小脚本很容易被认为是配置管理，尽管是在基础级别。

这些工具是您在旅途中会遇到的一些最好的工具，尤其是 Git，它的使用非常普遍，所以理解起来很好。

# 技术要求

在本章中，我们将需要几台**虚拟机** ( **虚拟机**)。

请随意使用下面的`Vagrantfile`。我们将主要在虚拟机之间的专用网络上工作:

```
# -*- mode: ruby -*-
# vi: set ft=ruby :

$provisionScript = <<-SCRIPT
sed -i 's#PasswordAuthentication no#PasswordAuthentication yes#g' /etc/ssh/sshd_config
systemctl restart sshd
SCRIPT

Vagrant.configure("2") do |config|

  config.vm.provision "shell",
    inline: $provisionScript

  config.vm.define "centos1" do |centos1|
    centos1.vm.box = "centos/7"
    centos1.vm.network "private_network", ip: "192.168.33.10"
    centos1.vm.hostname = "centos1"
    centos1.vm.box_version = "1804.02"
  end

  config.vm.define "centos2" do |centos2|
    centos2.vm.box = "centos/7"
    centos2.vm.network "private_network", ip: "192.168.33.11"
    centos2.vm.hostname = "centos2"
    centos2.vm.box_version = "1804.02"
  end

end
```

# Git 是什么？

在这一节中，我们将看看最高霸主在**版本控制系统** ( **VCSs** )方面的表现。还有其他的，未来还会有更多，但现在，有 Git，它是迄今为止使用最广泛、最受欢迎的(尽管也有不少批评)。

Git 最初是由 Linus Torvalds 开发的——没错，就是启动 Linux 内核开发的 Linus Torvalds，尽管现在它主要是由 Junio C Hamano 和许多其他天才黑客开发的。它主要出现在软件开发中，但越来越多地被用于存储像 Ansible、Terraform 和任何其他基础设施的配置，作为代码工具，支持您的基础设施的历史和版本图片。

# 准备好了

为了理解 Git，我们将安装它并启动您的虚拟机，然后跳到您的第一个 CentOS 框:

```
$ vagrant up
$ vagrant ssh centos1
```

# 怎么做...

安装 Git 很简单，因为它在大多数默认存储库中(事实上，我还没有遇到一个 Linux 发行版不在默认存储库中):

```
$ sudo yum install git -y
```

Warning: You will most likely get Perl, and while this is not inherently a bad thing, the very mention of the word perl can make developers and sysadmins alike cringe. 

我们现在应该有 Git 了，所以让我们来看看一些基础知识。

# 克隆

从根本上说，Git 是一个版本控制系统，主要用于源代码版本控制(尽管它也有其他用途)。

为了演示它是如何工作的，让我们克隆一个小一点的存储库(在本例中是 Ansible):

```
$ git clone https://github.com/ansible/ansible.git
Cloning into 'ansible'...
```

根据您的连接情况，这可能需要几分钟时间，但是一旦完成，您将会看到一个`ansible`文件夹:

```
$ ls -l
total 4
drwxrwxr-x. 14 vagrant vagrant 4096 Nov 19 18:10 ansible
```

# 探索并做出改变

我们现在有了类似的`devel`可翻译代码分支。它是`devel`，因为这是存储库所有者想要的默认分支，尽管通常是`master`或`develop`。

查看文件夹内部，我们会看到许多文件，其中包含大量代码:

```
$ cd ansible/
$ ls -l
total 100
drwxrwxr-x. 2 vagrant vagrant 243 Nov 19 18:10 bin
drwxrwxr-x. 3 vagrant vagrant 141 Nov 19 18:10 changelogs
-rw-rw-r--. 1 vagrant vagrant 645 Nov 19 18:10 CODING_GUIDELINES.md
drwxrwxr-x. 4 vagrant vagrant 53 Nov 19 18:10 contrib
-rw-rw-r--. 1 vagrant vagrant 35148 Nov 19 18:10 COPYING
drwxrwxr-x. 6 vagrant vagrant 60 Nov 19 18:10 docs
drwxrwxr-x. 4 vagrant vagrant 192 Nov 19 18:10 examples
drwxrwxr-x. 5 vagrant vagrant 4096 Nov 19 18:10 hacking
drwxrwxr-x. 3 vagrant vagrant 21 Nov 19 18:10 lib
drwxrwxr-x. 2 vagrant vagrant 78 Nov 19 18:10 licenses
-rw-rw-r--. 1 vagrant vagrant 13512 Nov 19 18:10 Makefile
-rw-rw-r--. 1 vagrant vagrant 852 Nov 19 18:10 MANIFEST.in
-rw-rw-r--. 1 vagrant vagrant 286 Nov 19 18:10 MODULE_GUIDELINES.md
drwxrwxr-x. 11 vagrant vagrant 133 Nov 19 18:10 packaging
-rw-rw-r--. 1 vagrant vagrant 5370 Nov 19 18:10 README.rst
-rw-rw-r--. 1 vagrant vagrant 360 Nov 19 18:10 requirements.txt
-rw-rw-r--. 1 vagrant vagrant 11028 Nov 19 18:10 setup.py
-rw-rw-r--. 1 vagrant vagrant 3389 Nov 19 18:10 shippable.yml
drwxrwxr-x. 10 vagrant vagrant 121 Nov 19 18:10 test
-rw-rw-r--. 1 vagrant vagrant 1129 Nov 19 18:10 tox.ini
```

和任何好的源代码一样，应该有一个`README`文件，这通常是一个很好的开始，但是我们现在不是为了 Ansible 我们是为了 Git。

运行一个`git status`:

```
$ git status
# On branch devel
nothing to commit, working directory clean
```

这告诉我们，我们没有进行任何更改，因此，我们的工作目录是干净的，因为我们还没有做任何事情。

对`README`文件进行以下更改:

```
$ sed -i 's/^/The big brain am winning again. /g' README.rst 
```

现在，如果我们再次应用`git status`，我们将看到我们的变化:

```
$ git status
# On branch devel
# Changes not staged for commit:
# (use "git add <file>..." to update what will be committed)
# (use "git checkout -- <file>..." to discard changes in working directory)
#
# modified: README.rst
#
no changes added to commit (use "git add" and/or "git commit -a")
```

正如消息所暗示的，我们可以添加并提交我们的更改，然后尝试将它们合并到上游(不要)，但是现在，我们将简单地恢复我们刚刚完成的更改，该更改破坏了`README`文件。

首先，让我们看看我们做了什么:

```
$ cat README.rst 
The big brain am winning again. |PyPI version| |Docs badge| |Chat badge| |Build Status| |Code Of Conduct| |Mailing Lists| |License|
The big brain am winning again. 
The big brain am winning again. *******
The big brain am winning again. Ansible
The big brain am winning again. *******
The big brain am winning again. 
The big brain am winning again. Ansible is a radically simple IT automation system. It handles
<SNIP>
```

哦，亲爱的——让我们解决这个问题:

```
$ git checkout README.rst 
$ git status
# On branch devel
nothing to commit, working directory clean
```

注意，当我们签出`README`文件时，我们基本上将文件重置为默认状态，这意味着 git 不认为我们有什么要提交的，文件恢复正常。

Checking out is the act of overwriting our uncommitted local changes with the Git repository's version.

我们可以看到，这些更改已经通过再次复制文件而被还原:

```
$ head -5 README.rst
|PyPI version| |Docs badge| |Chat badge| |Build Status| |Code Of Conduct| |Mailing Lists| |License|

*******
Ansible
*******
```

整洁，嗯？

但是，值得记住的是，在覆盖文件之前所做的任何更改都将丢失(因为它们没有被转移，并且存储库没有意识到它们)。

# 它是如何工作的...

从根本上说，Git 是一个版本控制系统，这意味着它控制着它所管理的文件的版本。

理论上，大多数文件夹都可以成为 Git 存储库，尽管通常是代码或配置获得了这种特权。

当您签出一个存储库时，您会得到一个快照，显示您签出时分支上的代码在哪里。如果您随后进行了更改，则这些更改需要暂存并保存在单独的分支中，或者合并到您更改的分支中。

Don't worry too much about this yet—I was incredibly confused the first time someone told me about Git.

在现实世界中，人们倾向于使用 Git 的方式有很多种，一些相对流行的工具和实践已经被开发出来。例如，使用 Git 的内核方法与 GitFlow 方法截然不同。

我们将在本章的剩余部分讨论变更的例子，但是现在，您只需要理解，如果您提交某个东西并将其推送到 Git 存储库中，它将记录该变更，这意味着您可以在存储库生命周期的任何时候返回到代码的早期版本，并将旧的修复或后台更改复制到稳定的分支中。

Sadly, Git doesn't have the ability to import code you haven't written yet from some weird future file, but I'm still holding out hope for this feature. 

每个存储库的配置都存储在`.git`文件夹中，该文件夹是在导入/创建存储库时创建的:

```
$ pwd
/home/vagrant/ansible
$ ls -hla .git
total 1.5M
drwxrwxr-x. 8 vagrant vagrant 163 Nov 19 18:17 .
drwxrwxr-x. 14 vagrant vagrant 4.0K Nov 19 18:17 ..
drwxrwxr-x. 2 vagrant vagrant 6 Nov 19 18:09 branches
-rw-rw-r--. 1 vagrant vagrant 261 Nov 19 18:10 config
-rw-rw-r--. 1 vagrant vagrant 73 Nov 19 18:09 description
-rw-rw-r--. 1 vagrant vagrant 22 Nov 19 18:10 HEAD
drwxrwxr-x. 2 vagrant vagrant 242 Nov 19 18:09 hooks
-rw-rw-r--. 1 vagrant vagrant 1.4M Nov 19 18:17 index
drwxrwxr-x. 2 vagrant vagrant 21 Nov 19 18:09 info
drwxrwxr-x. 3 vagrant vagrant 30 Nov 19 18:10 logs
drwxrwxr-x. 4 vagrant vagrant 30 Nov 19 18:09 objects
-rw-rw-r--. 1 vagrant vagrant 28K Nov 19 18:10 packed-refs
drwxrwxr-x. 5 vagrant vagrant 46 Nov 19 18:10 refs
```

该文件夹还包含存储库的历史记录(二进制格式)。当您试图在不在您的已签出分支中的文件中查找更改和差异时，会搜索该位置。因此，它也可以相当大。

查看配置文件，我们可以看到克隆存储库时得出的默认值:

```
$ cat .git/config 
[core]
 repositoryformatversion = 0
 filemode = true
 bare = false
 logallrefupdates = true
[remote "origin"]
 url = https://github.com/ansible/ansible.git
 fetch = +refs/heads/*:refs/remotes/origin/*
[branch "devel"]
 remote = origin
 merge = refs/heads/devel
```

请注意远程部分，详细说明我们的`origin`所在的位置。

There's also a `global` configuration file and a `system` file that can be used to make changes that affect every repository your user interacts with, along with every repository any user on the system interacts with.

这应该给你一个很好的提示，为什么 Git 如此伟大——它允许轻松的协作，因为人们可以在不同的分支甚至同一个分支上工作，并且有适当的功能来阻止你在彼此的工作上盖章。您还可以在知道文件历史记录在那里的情况下安全地进行更改，这意味着当您不可避免地损坏某个东西时，您可以通过几次击键来修复它。

# 还有更多...

Git 非常强大，但是它也有一些非常好的功能。

例如，`log`对于读取提交消息非常有用:

```
$ git log --pretty=short 
```

输出应该如下图所示:

![](assets/ff6c981d-7bbd-454e-8418-ed7de204081c.png)

`tag`对于列出人们在代码的不同时间点添加的标签非常有用:

```
$ git tag | head -n5
0.0.1
0.0.2
0.01
0.3
0.3.1
```

`branch`可以用来查看 Git 知道的所有不同分支:

```
$ git branch -a
* devel
 remotes/origin/HEAD -> origin/devel
 remotes/origin/acozine-patch-1
 remotes/origin/devel
 remotes/origin/mazer_role_loader
 remotes/origin/release1.5.0
 remotes/origin/release1.5.1
 remotes/origin/release1.5.2
<SNIP>
```

在这里，我们使用了`-a`，所以包括了远程分支，以及您的单个本地分支(`devel`)。

# 设置 Git 服务器

在这一节中，我们将看看如何设置一个小型的 Git 服务器，实际上使用我们从 CentOS 存储库中安装`git`时所获得的内容。

我们将在 centos2 上创建一个基本存储库，并从 centos1 开始使用它。

# 准备好

在本节中，我们将使用两台机器，使用 centos2 作为服务器，centos1 作为客户端。

在这种情况下，请确保您的两台机器上都安装了`git`:

```
$ sudo yum install git -y
```

# 怎么做...

在`centos2`上，让我们创建我们的空存储库:

```
$ mkdir example.git
$ cd example.git/
$ git init --bare
Initialized empty Git repository in /home/vagrant/example.git/
```

现在，在我们的`centos1`机器上，我们可以克隆存储库:

```
$ git clone 192.168.33.11:example.git
Cloning into 'example'...
The authenticity of host '192.168.33.11 (192.168.33.11)' can't be established.
ECDSA key fingerprint is SHA256:s5NfsrM/XRuH5rXaZSaNmaUxXe3MlN2wRoJ3Q43oviU.
ECDSA key fingerprint is MD5:ea:24:ef:b3:cf:d9:03:3d:06:da:1f:2f:d2:6b:1d:67.
Are you sure you want to continue connecting (yes/no)? yes
Warning: Permanently added '192.168.33.11' (ECDSA) to the list of known hosts.
vagrant@192.168.33.11's password: 
warning: You appear to have cloned an empty repository.
```

系统会提示您输入`vagrant`用户密码(默认为`vagrant`，然后您会看到一条消息，通知您已经克隆了一个空的存储库。

不过这很好，因为您现在应该看到一个新的`example`目录:

```
$ ls
example
$ cd example/
$ git status
# On branch master
#
# Initial commit
#
nothing to commit (create/copy files and use "git add" to track)
```

# 它是如何工作的...

当您在 centos2 上初始化您的存储库时，您正在创建第一个存储库，该存储库可以存在于任何数量的设备上，并且不必从您的中心位置(centos2)进行克隆。

If, for some reason, you're in a situation where you can't clone from the initial server (centos2), you could also clone the repository from another machine that already had the repository checked out (though you do run the risk of that repository not being up to date with the first node).

当您克隆存储库时，您实际上是通过 SSH 与`centos2`框进行通信，Git 发送特定的命令，这些命令被另一端的存储库理解并应答。

同样，如果我们在克隆的存储库中查看`centos1`上的`.git`存储库，我们可以看到以下内容:

```
$ cat .git/config 
[core]
 repositoryformatversion = 0
 filemode = true
 bare = false
 logallrefupdates = true
[remote "origin"]
 url = 192.168.33.11:example.git
 fetch = +refs/heads/*:refs/remotes/origin/*
[branch "master"]
 remote = origin
 merge = refs/heads/master
```

注意打印为遥控器的网址`origin`。还要注意，这不是一个`bare`存储库。

我们来看看服务器上的`config`文件(`centos2`):

```
$ cat config 
[core]
 repositoryformatversion = 0
 filemode = true
 bare = true
```

它要小得多，这里`bare`设置为`true`。

# 还有更多...

这是最简单的 Git 存储库，如果你想让它更有趣，还可以做更多的事情。

首先，您可以考虑在您的系统上创建一个专用的`git`用户，并将其用作管理和拥有 Git 存储库的用户。这通常是一种非常标准的方法，并且是现成的 Git 解决方案所共有的，比如 GitLab 和 GitHub。

其次，你可以考虑建立一个`cgit`服务器，这是一个可以用来可视化 Git 存储库的小型服务器。

最著名的`cgit`例子可能是[git.kernel.org](https://git.kernel.org/):

![](assets/50656c38-f1d5-431e-8307-6138b86432bb.png)

# 提交到我们的 Git 存储库

在这一节中，我们将把一个小文件放在一起，将其添加到 Git 正在跟踪的文件中，提交我们的更改，并将它们推送到原始服务器。

# 准备好了

如果您还没有这样做，请根据上一节设置一个 Git 服务器。

确保您已经在`centos1`上签出了您的存储库。

# 怎么做...

让我们给我们的新存储库一点信息，并将其推送到服务器(证明它是有效的):

```
$ cd example/
```

让我们从运行一个`git status`开始，看看我们在哪里:

```
$ git status
# On branch master
nothing to commit, working directory clean
```

很好——它是空的。

现在，让我们将一些文本回显到一个文件中，暂存该文件，并用一条消息提交它:

```
$ echo "Warcraft III was the best Warcraft game." > README
$ git add README
$ git commit -m "Adding README to repository." 

*** Please tell me who you are.

Run

 git config --global user.email "you@example.com"
 git config --global user.name "Your Name"

to set your account's default identity.
Omit --global to set the identity only in this repository.

fatal: unable to auto-detect email address (got 'vagrant@centos1.(none)')
```

啊！现在，因为这是一个新的安装，Git 提示我们设置一些默认值:

```
$ git config --global user.email "you@example.com"
$ git config --global user.name "Your Name... good film."
```

让我们再次尝试该提交:

```
$ git commit -m "Adding README to repository." 
[master (root-commit) 65bf49a] Adding README to repository.
 1 file changed, 1 insertion(+)
 create mode 100644 README
```

好的，我们已经提交了文件，这意味着`master`的本地版本是最新的。

然而，这意味着我们现在与我们的原始存储库不同步，所以我们也需要`push`我们的更改到那里:

```
$ git push
warning: push.default is unset; its implicit value is changing in
Git 2.0 from 'matching' to 'simple'. To squelch this message
and maintain the current behavior after the default changes, use:

 git config --global push.default matching

To squelch this message and adopt the new behavior now, use:

 git config --global push.default simple

See 'git help config' and search for 'push.default' for further information.
(the 'simple' mode was introduced in Git 1.7.11\. Use the similar mode
'current' instead of 'simple' if you sometimes use older versions of Git)
```

呜！另一个提示—我们应该设置它。就我个人而言，我选择了新的行为，因为尽管 CentOS 7 搭载了旧版本的 Git，但进步的步伐仍在继续:

```
$ git config --global push.default simple
```

唷！好吧，让我们再试一次:

```
$ git push
vagrant@192.168.33.11's password: 
Counting objects: 3, done.
Writing objects: 100% (3/3), 268 bytes | 0 bytes/s, done.
Total 3 (delta 0), reused 0 (delta 0)
To 192.168.33.11:example.git
 * [new branch] master -> master
```

在这里，您可以看到系统提示我们输入密码，但是一旦输入了密码，更改就会被写入原始服务器。

这意味着，当我们再次从原点克隆存储库时，我们的更改也会随之而来。

从您的主目录中尝试以下内容来证明这一点:

```
$ cd ~
$ git clone 192.168.33.11:example.git example2
Cloning into 'example2'...
vagrant@192.168.33.11's password: 
remote: Counting objects: 3, done.
remote: Total 3 (delta 0), reused 0 (delta 0)
Receiving objects: 100% (3/3), done.
$ ls example2
README
```

精益求精！

# 它是如何工作的...

在这里，我们正在做一些事情。

首先，在我们创建了包含一些文本的 foo 文件之后，我们`add`该文件:

```
$ git add README
```

在这个小命令中，我们实际上是将`README`文件添加到 Git 的索引中。

我们以这种方式提交的任何内容都会添加到下一个提交中:

```
$ git commit -m "Adding README to repository." 
```

在这里，我们向存储库提交(顾名思义)我们添加的更改。我们还将一条消息作为命令的一部分(带有`-m`)，而不是让`git commit`将我们放入默认编辑器设置的任何位置(因为每个提交都应该有一条消息，因为它会提示您编写一条消息)。

最后，我们推动了我们的变革:

```
$ git push
```

用技术术语来说，我们正在通知远程存储库(在`192.168.33.11`上)一些引用已经改变，我们告诉它是哪些引用。我们还将这些被引用的更改推送到任何相关的对象。

# 匹配与简单

一个简短的词，因为我们在这部分设置了我们的默认值。

如果我们将选项设置为匹配，那么当运行`git push`命令时，我们将一次推送所有分支。这意味着不仅是你现在的分支，还有`master`、`develop`，以及你可能拥有的任何其他分支也会被推。

另一方面，Simple 只会推送您当前正在处理的分支。从逻辑的角度来看，简单是默认行为是可以理解的，因为它假设大多数人在任何时候都只在一个分支工作。

# 分支我们的 Git 存储库并提交更改

在本节中，我们将研究如何将克隆的存储库分支，并将这些更改推送到我们的服务器上。

# 准备好

确保您至少已经运行了*设置*部分，但最好也是提交第一个文件的部分。

所有工作都将在`example`存储库中的`centos1`上完成。

# 怎么做...

进入`example`储存库:

```
$ cd ~/example
```

现在，检查您是否在`master`开始:

```
$ git branch
* master
```

Your current branch is denoted with an asterisk. 

很好！现在，我们将从`master`关闭`branch`，并进行一些更改:

```
$ git branch develop
```

再次运行`git branch`:

```
$ git branch
 develop
* master
```

请注意，现在我们有两个分支，但我们仍然在`master`分支上。我们需要运行一个不同的命令来切换到我们的新分支:

```
$ git checkout develop
Switched to branch 'develop'
```

现在，列出这个分支的内容:

```
$ ls
README
```

我们有效地复制了`master`分支，这意味着提交给该分支的所有文件在我们的新分支中都是可用的。

让我们创建一个新文件并给它一些内容:

```
$ echo "Keep your keys happy." > RULESFORRULERS
```

运行`git status`再次通知我们未跟踪的变化:

```
$ git status
# On branch develop
# Untracked files:
# (use "git add <file>..." to include in what will be committed)
#
# RULESFORRULERS
nothing added to commit but untracked files present (use "git add" to track)
```

如其所言，我们来`add`和`commit`这个文件:

```
$ git add *
$ git commit -m "Adding an extremely important file\!"
[develop 7f91f4d] Adding an extremely important file\!
 1 file changed, 1 insertion(+)
 create mode 100644 RULESFORRULERS
```

我们现在在本地有了一个分支，提交的文件根本不在源服务器上。

让我们试试`push`我们的分支到`192.168.33.11`:

```
$ git push
fatal: The current branch develop has no upstream branch.
To push the current branch and set the remote as upstream, use

 git push --set-upstream origin develop
```

哦不！

因为我们本地`develop`分公司没有配置上游对应方，`push`失败。

但是，您已经知道这一点，因为您是一个勤奋的系统管理员，并且您实际上已经阅读了错误消息，以及它为我们提供的纠正此问题的有用命令:

```
$ git push --set-upstream origin develop
vagrant@192.168.33.11's password: 
Counting objects: 4, done.
Compressing objects: 100% (2/2), done.
Writing objects: 100% (3/3), 326 bytes | 0 bytes/s, done.
Total 3 (delta 0), reused 0 (delta 0)
To 192.168.33.11:example.git
 * [new branch] develop -> develop
Branch develop set up to track remote branch develop from origin. 
```

好的，我们现在在本地有一个`develop`和`master`分支，以及上游服务器上的一个副本。

让我们来看看`master`现在的样子:

```
$ git checkout master
Switched to branch 'master'
$ ls
README
```

什么事？我们的文件呢？它在这个目录里！

啊，但是不，这是同一个目录的不同分支，而且，在这个黑暗的时间线里，我们的工作不存在。

让我们检查一下我们两个分支之间的差异:

```
$ git diff develop
diff --git a/RULESFORRULERS b/RULESFORRULERS
deleted file mode 100644
index c895005..0000000
--- a/RULESFORRULERS
+++ /dev/null
@@ -1 +0,0 @@
-Keep your keys happy.
```

这是我们的工作！

好吧，那么如果我们想从`develop`开始合并我们的变更呢？

Git 是这样做的:

```
$ git merge develop
Updating 65bf49a..7f91f4d
Fast-forward
 RULESFORRULERS | 1 +
 1 file changed, 1 insertion(+)
 create mode 100644 RULESFORRULERS
$ ls
README RULESFORRULERS
```

轰！我们仍然在我们的`master`分支上，但是文件回来了。

然而，令人困惑的是，如果我们现在运行`git status`，我们会看到一个新的信息:

```
$ git status
# On branch master
# Your branch is ahead of 'origin/master' by 1 commit.
# (use "git push" to publish your local commits)
#
nothing to commit, working directory clean
```

值得庆幸的是，这一信息很好，很有解释力。我们当地的`master`分公司还好，但是`upstream`还没有意识到我们的变化。

我们可以用另一个`diff`证明这一点:

```
$ git diff origin/master
diff --git a/RULESFORRULERS b/RULESFORRULERS
new file mode 100644
index 0000000..c895005
--- /dev/null
+++ b/RULESFORRULERS
@@ -0,0 +1 @@
+Keep your keys happy.
```

让我们把我们的改变放在那里:

```
$ git push
vagrant@192.168.33.11's password: 
Total 0 (delta 0), reused 0 (delta 0)
To 192.168.33.11:example.git
 65bf49a..7f91f4d master -> master
```

魔法。

# 它是如何工作的...

好吧，所以这不是真正的魔法，只是一些极其出色的编码的产物。

当我们从`master`(或者任何分支)分支时，我们在新的分支中创建了该分支的时间点克隆。然后，我们对分支进行了更改，比如测试配置更改，或者有目的地中断，而不影响`master`分支(以及我们已知的良好配置)。

这很容易理解(我认为)，但是当我们想要确保我们的更改被推送到服务器时，问题就开始了。

我们跑`git push`，它抱怨。这是因为我们的。git/config 文件，它告诉 git 将我们的本地分支推到哪里。

运行建议的命令后，我们的`.git/config`现在看起来如下:

```
$ cat .git/config 
[core]
 repositoryformatversion = 0
 filemode = true
 bare = false
 logallrefupdates = true
[remote "origin"]
 url = 192.168.33.11:example.git
 fetch = +refs/heads/*:refs/remotes/origin/*
[branch "master"]
 remote = origin
 merge = refs/heads/master
[branch "develop"]
 remote = origin
 merge = refs/heads/develop
```

请注意包含了新的分支定义。

所以，推送完成，远程看起来不错。

然后我们返回到`master`并执行我们的`git diff`命令:

```
$ git diff develop
diff --git a/RULESFORRULERS b/RULESFORRULERS
deleted file mode 100644
index c895005..0000000
--- a/RULESFORRULERS
+++ /dev/null
@@ -1 +0,0 @@
-Keep your keys happy.
```

这应该是合理的不言自明的，但是我们正在对我们现在所在的分支以及指定的分支执行`diff`。

您可以使用下面的语法实现同样的事情，它稍微显式一点:

```
$ git diff master..develop
```

或者，您甚至可以检查您不在的两个分支:

```
$ git diff origin/master..origin/develop
```

这样，我们开始看到 Git 作为一个开发工具有多强大。

它还巧妙地让我开始谈论`origin`分支。

在本节中，我们将我们的本地主机与`origin/master`进行了比较，如下所示:

```
$ git diff origin/master
diff --git a/RULESFORRULERS b/RULESFORRULERS
new file mode 100644
index 0000000..c895005
--- /dev/null
+++ b/RULESFORRULERS
@@ -0,0 +1 @@
+Keep your keys happy.
```

从我们的`.git/config`中，我们了解到`origin`是远程存储库的名称，就 Git 而言:

```
[remote "origin"]
  url = 192.168.33.11:example.git
  fetch = +refs/heads/*:refs/remotes/origin/*
```

因此，`origin/master`是`remote`服务器上的`master`分支。

我们对`origin/master`(以`git push`的形式)的推送使我们的代码保持最新。

# 还有更多...

你可能会想，如果你只是打算将你的分支机构合并到`master`中，为什么你还要费力地推进`remote`分支机构。

答案很简单:在大多数环境中，你最终会和很多其他人一起工作，能够展示你已经改变了什么以及你正在做什么是一个很好的开发工具。它还允许在合并之前进行分支机构内的协作，因为任何人都可以自己检查您的分支机构。

同样真实的是，大多数人并不只是在他们的基础设施中使用一个 Git 服务器，而是寻找像 Gogs 和 GitLab 这样的解决方案，它们是具有附加功能(比如用户管理)的 Git 服务器。

您也可以考虑服务器，并意识到在这一部分中，它有点拖沓，并不是真正需要的。

让我们先创建并签出一个新分支，快速了解一下服务器的变化:

```
$ git checkout -b super-fixes
Switched to a new branch 'super-fixes'
```

I used the shorthand for creating and checking out a branch here, adding `-b` to the `git checkout` command. There's hundreds of little tricks with Git, and people tend to have their favorites.

在这个分支中，让我们创建一个新文件并将其`push``upstream`:

```
$ echo "Never look tired." > RULESFORRULERS
$ git commit -am "Another git trick, adding and committing in one line." 
[super-fixes a9b53e8] Another git trick, adding and committing in one line.
 1 file changed, 1 insertion(+), 1 deletion(-)
$ git push --set-upstream origin super-fixes
vagrant@192.168.33.11's password: 
Counting objects: 5, done.
Compressing objects: 100% (2/2), done.
Writing objects: 100% (3/3), 329 bytes | 0 bytes/s, done.
Total 3 (delta 0), reused 0 (delta 0)
To 192.168.33.11:example.git
 * [new branch] super-fixes -> super-fixes
Branch super-fixes set up to track remote branch super-fixes from origin.
```

接下来，翻到`centos2`并进入储存库:

```
$ cd ~/example.git/
```

通过运行`ls`，您将看不到您的实际文件:

```
$ ls
branches config description gitweb HEAD hooks info objects pid refs
```

相反，您的文件在`objects`目录中，以当前格式不可读:

```
$ ls objects/
1c 29 65 7f 84 a5 a9 b0 c8 info pack
```

我们可以通过树枝看到它们:

```
$ ls refs/heads/
develop master super-fixes
```

您不会在服务器上的裸存储库中工作——您会在另一台机器上克隆和调整您的存储库——但是偶尔查看一下内部工作是很好的。

# 请参见

您可能想要安装 GitLab，或者 Gogs，或者任何其他的 GUI-Git 实现，以便您可以使用它们。就我个人而言，我发现它们相当直观，当团队有一个共同鄙视的图形用户界面而不是一系列控制台命令时，团队往往会工作得更好。

# 安装 Ansible

在这一节中，我们将看看 Ansible 形式的最流行的配置管理工具之一。像其他人(如厨师、木偶和盐)一样，Ansible 是一种编码您的服务器配置的方式，我的意思是您想要做的任何更改都可以写入一个文件，并通过编程应用于服务器或服务器的集合。

您放在一起的配置文件可以保存到一个中央存储中，最常见的是 Git，您可以围绕您的配置构建自动管道等东西，以便自动应用对该配置的更改。

在默认情况下，您的 Ansible 从基础架构中的指定盒子(通常是 GitLab、Jenkins 或 Ansible Tower 安装)运行，或者在较小的环境中运行。看到工程师在自己的机器上进行更改并不罕见。

Ansible isn't just for servers with modules that cover a wide range of scenarios, such as cloud provider configuration, switch configuration, and even certificate management.

我们将在 centos1 上运行一些小的 Ansible 命令，将更改应用到 centos2。

# 准备好

打开与`centos1`机器的连接，同时安装 Ansible:

```
$ vagrant ssh centos1 $ sudo yum install ansible ansible-doc -y
```

# 怎么做...

首先，我们将检查我们已经安装的 Ansible 版本:

```
$ ansible --version
ansible 2.4.2.0
 config file = /etc/ansible/ansible.cfg
 configured module search path = [u'/home/vagrant/.ansible/plugins/modules', u'/usr/share/ansible/plugins/modules']
 ansible python module location = /usr/lib/python2.7/site-packages/ansible
 executable location = /usr/bin/ansible
 python version = 2.7.5 (default, Apr 11 2018, 07:36:10) [GCC 4.8.5 20150623 (Red Hat 4.8.5-28)]
```

这是版本`2.4.2.0`。

与标准存储库中的许多包一样，它们往往是稳定的(较旧的)版本。如果你愿意，也可以安装`pip`(包含在[第 11 章](11.html)、网络服务器、数据库和邮件服务器中)，并使用它来安装更新版本的 Ansible。现在，我们将继续使用`2.4.2.0`。

为了测试我们的连通性是否存在，我们可以使用一个名为`ping`的默认 Ansible 模块(尽管这不是 ICMP)。系统会提示您输入`SSH password`(流浪者):

```
$ ANSIBLE_HOST_KEY_CHECKING=false ansible -k -m ping -i 192.168.33.11, 192.168.33.11
SSH password: 
192.168.33.11 | SUCCESS => {
 "changed": false, 
 "ping": "pong"
}
```

We add the 'ANSIBLE_HOST_KEY_CHECKING=false' variable to ensure the remote machine's SSH host key get's accepted when we run our command. Subsequent commands shouldn't require this. In a production scenario, you should always confirm you trust the remote machine's key.

太棒了。我们的`centos2`框做出了响应，更好的是，我们的命令告诉我们，这并没有导致远程机器的改变(稍后将对此进行详细介绍)。

接下来，让我们尝试使用不同的模块安装一些东西。我们想安装一个软件包，但是不知道怎么安装。

为此，您可以访问 Ansible 网站([https://docs . ansi ble . com/ansi ble/latest/modules/list _ of _ all _ modules . html](https://docs.ansible.com/ansible/latest/modules/list_of_all_modules.html))并搜索`package`，也可以使用`ansible-doc`:

```
$ ansible-doc -l
```

运行时，您将被放入一个寻呼机，以及所有可用 Ansible 模块的列表。运行对`package`的搜索(键入`/`字符，后跟搜索字符串)，并继续搜索，直到找到该名称的模块:

![](assets/4825c804-0d1f-4b06-b2c1-392d931370a4.png)

There's no guarantee that a module exists for the functionality you want, but there's also a good chance it does. Search for keywords that relate to what you're trying to do, and, nine times out of ten, you might be pleasantly surprised. 

假设你已经发现包模块叫做`package`，你可以退出这个寻呼机。

现在，让我们看看`package`的语法是什么:

```
$ ansible-doc -s package
- name: Generic OS package manager
 package:
 name: # (required) Package name, or package specifier with version, like `name-1.0'. Be aware that packages are not always named the same and this module will not 'translate' them
 per distro.
 state: # (required) Whether to install (`present', or remove (`absent') a package. Other states depend on the underlying package module, i.e `latest'.
 use: # The required package manager module to use (yum, apt, etc). The default 'auto' will use existing facts or try to autodetect it. You should only use this field if the
 automatic selection is not working for some reason.
```

这看起来很好，它告诉我们的是，需求正是我们需要的，以便`name`包装，并规定它应该处于什么状态。

太棒了！我们可以利用这些知识:

```
$ ansible -b -k -m package -a 'name=zip state=present' -i 192.168.33.11, 192.168.33.11
SSH password: 
192.168.33.11 | SUCCESS => {
    "changed": true, 
    "msg": "warning: /var/cache/yum/x86_64/7/base/packages/zip-3.0-11.el7.x86_64.rpm: Header V3 RSA/SHA256 Signature, key ID f4a80eb5: NOKEY\nImporting GPG key 0xF4A80EB5:\n Userid : \"CentOS-7 Key (CentOS 7 Official Signing Key) <security@centos.org>\"\n Fingerprint: 6341 ab27 53d7 8a78 a7c2 7bb1 24c6 a8a7 f4a8 0eb5\n Package : centos-release-7-5.1804.el7.centos.x86_64 (@anaconda)\n From : /etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7\n", 
    "rc": 0, 
    "results": [
        "Loaded plugins: fastestmirror\nLoading mirror speeds from cached hostfile\n * base: mirrors.vooservers.com\n * extras: mirror.sov.uk.goscomb.net\n * updates: mirror.sov.uk.goscomb.net\nResolving Dependencies\n--> Running transaction check\n---> Package zip.x86_64 0:3.0-11.el7 will be installed\n--> Finished Dependency Resolution\n\nDependencies Resolved\n\n================================================================================\n Package Arch Version Repository Size\n================================================================================\nInstalling:\n zip x86_64 3.0-11.el7 base 260 k\n\nTransaction Summary\n================================================================================\nInstall 1 Package\n\nTotal download size: 260 k\nInstalled size: 796 k\nDownloading packages:\nPublic key for zip-3.0-11.el7.x86_64.rpm is not installed\nRetrieving key from file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7\nRunning transaction check\nRunning transaction test\nTransaction test succeeded\nRunning transaction\n Installing : zip-3.0-11.el7.x86_64 1/1 \n Verifying : zip-3.0-11.el7.x86_64 1/1 \n\nInstalled:\n zip.x86_64 0:3.0-11.el7 \n\nComplete!\n"
    ]
}
```

We could have also included `-K` if the sudo action required a password on the remote machine, ours didn't.

酷！所以我们设法使用 Ansible 在我们的远程机器上安装了`zip`包(我将让读者来猜测这个包是做什么的)。让我们再次运行该命令—会发生什么？它会重新安装软件包吗？

```
$ ansible -b -k -m package -a 'name=zip state=present' -i 192.168.33.11, 192.168.33.11
SSH password: 
192.168.33.11 | SUCCESS => {
    "changed": false, 
    "msg": "", 
    "rc": 0, 
    "results": [
        "zip-3.0-11.el7.x86_64 providing zip is already installed"
    ]
} 
```

事实证明，不，Ansible 不会重新安装软件包。如果你愿意的话，这是 Ansible 的基本理念之一。针对远程主机运行的作业应该是幂等的，也就是说，它们不应该在不需要时进行任何更改。

在编写 Ansible 时，最好确保您编写的代码是幂等的，而不是让它在每次运行时都进行更改。如果不断进行更改，代码将不会是幂等的，并且您永远无法保证系统的状态。

Sometimes, especially when executing straight commands on a remote system, idempotence will have to be thought about carefully, and occasionally manually constructed into the logic of your Ansible runs, though this is a more advanced discipline. Even I occasionally defer to far smarter friends on the subject.

为了完整起见，让我们做最后一件事:

```
$ ansible -b -k -m yum -a 'name=zip state=present' -i 192.168.33.11, 192.168.33.11
SSH password: 
192.168.33.11 | SUCCESS => {
    "changed": false, 
    "msg": "", 
    "rc": 0, 
    "results": [
        "zip-3.0-11.el7.x86_64 providing zip is already installed"
    ]
} 
```

你能指出这个命令和我们上一个命令的区别吗？

好吃极了！

具体来说，我们现在所做的是使用 Ansible `yum`模块代替`package`，这意味着我们还没有做到让我们的命令只在基于 YUM 的系统上工作。这强调了实现相同目标的方法不止一种，我们将讨论为什么您可能希望很快使用这两个模块。

# 它是如何工作的...

现在，我们已经快速了解了 Ansible 如何用于在远程机器上运行作业，让我们从`ping`模块开始，详细介绍我们所做的工作:

```
$ ANSIBLE_HOST_KEY_CHECKING=false ansible -k -m ping -i 192.168.33.11, 192.168.33.11
```

让我们按顺序回顾一下这些论点:

```
-k
```

这里，`-k`表示 Ansible 将知道提示我们输入密码，我们将使用该密码连接到远程机器(我们的游民用户的 SSH 密码):

```
-m ping
```

在这里，我们告诉 Ansible 我们想要使用`ping`模块:

```
-i 192.168.33.11,
```

在这里，我们正在建立一个库存，尽管不可否认是一台机器的库存。

Ansible 需要知道它可以使用的主机列表—它的清单—但是在这里，我们只有一个，所以我们使用它(确保以逗号结尾):

```
192.168.33.11
```

最后，我们以我们试图击中的主机的 IP 结束，这有点违背直觉，我们必须重复。

One thing we are missing here is the `-u` flag, which we would use if we wanted to `SSH` to the remote host as a user that wasn't `vagrant`. 

既然来了，我们也来看看我们的第二个`ansible-doc`命令:

```
$ ansible-doc -s package
```

在这里，我们希望看到一段代码片段，我们可以编写它用于`package`模块。这在紧急情况下的服务器上非常有用，或者在你可能无法访问更广泛的互联网的考试情况下。

最后，让我们分解我们的最终命令(尽管同样的原理可以应用于`package`示例):

```
$ ansible -b -k -m yum -a 'name=zip state=present' -i 192.168.33.11, 192.168.33.11
```

这里有几个不同之处:

```
-b
```

我们在这里使用`-b`是因为我们正在做一个改变，需要我们在远程机器上“变成”。这意味着运行带有权限升级的命令(成为 root 用户)。

```
-m yum -a 'name=zip state=present'
```

这里，我们将`-a`添加到我们的参数列表中，特别是因为`yum`模块需要自己的参数，然后我们将这些参数放在引号中。

根据您使用的模块，这些参数可能会很长，但在这里相对较少。

我们第二次使用`yum`，特别强调的是，虽然实现了相同的目标(安装`zip`包)，但我们可以选择将我们的命令与特定的发行版联系起来。

当您查看`package`模块可用的参数列表时，原因很简单:

*   `name`
*   `state`
*   `use`

您也可以查看`yum`模块提供的帮助:

*   `allow_downgrade`
*   `conf_file`
*   `disable_gpg_check`
*   `disablerepo`
*   `enablerepo`
*   `exclude`
*   `installroot`
*   `list`
*   `name`
*   `security`
*   `skip_broken`
*   `state`
*   `update_cache`
*   `validate_certs`

希望你能看到`yum`模块如何被用来为 Ansible 编写更具体更详细的指令。

In the real world, I have seen engineers write code that attempts to satisfy all use cases with one role, that is, a role can be applied and accomplish the same thing on a Debian, CentOS, or Alpine system. This is perhaps a noble goal, but it usually results in immense frustration on the part of the engineer, or the engineer who comes next, due to inflexibility. Generally, I have found it easier to simply use the distro-specific modules, and get Ansible to check what sort of distro it's running on prior to choosing which commands to execute or, better yet, just use one distribution in your infrastructure instead of a mixture.

# 还有更多...

还有几件小事需要注意。

# 原始模块

在这种情况下，centos2 已经安装了 Python(Ansible 需要它才能在远程机器上运行模块)。但是，如果没有，您必须先将其安装在机器上，或者比任何其他模块先使用 Ansible 的内置`raw`模块。

当你使用`raw`时，你实际上是直接在远程机器上运行命令。这最常见的是一条类似于下面的线:

```
$ ansible -b -k -m raw -a 'whoami' -i 192.168.33.11, 192.168.33.11
SSH password: 
192.168.33.11 | SUCCESS | rc=0 >>
root
Shared connection to 192.168.33.11 closed.
```

请注意，远程机器仅使用`SUCCESS`和结果命令进行响应。

我们会用这个来安装`python`:

```
$ ansible -b -k -m raw -a 'yum install python -y' -i 192.168.33.11, 192.168.33.11
SSH password: 
192.168.33.11 | SUCCESS | rc=0 >>
Loaded plugins: fastestmirror
Loading mirror speeds from cached hostfile
<SNIP>
Updated:
 python.x86_64 0:2.7.5-69.el7_5 

Dependency Updated:
 python-libs.x86_64 0:2.7.5-69.el7_5 

Complete!
Shared connection to 192.168.33.11 closed.
```

它的格式不太好，但由于我们现在在`remote`机器上有`python`，我们将能够使用适当的可移植模块，而不是依赖简单的`SSH`执行。

# 外壳和命令模块

像`raw`一样，您可以使用 Ansible 将本机命令传递给远程机器(事实上，您可以非常容易地将整个 bash 脚本翻译成 Ansible 角色)，尽管通常这种类型的功能是为那些您绝对无法使用专用的 Ansible 模块来实现的情况保留的。

然而，这两个要求 Python 在远程机器上。

首先，我们来看看`shell`模块:

```
$ ansible -b -k -m shell -a 'whoami > BUTTER; cat BUTTER | rev' -i 192.168.33.11, 192.168.33.11
SSH password: 
192.168.33.11 | SUCCESS | rc=0 >>
toor
```

请注意，我基本上是在 Ansible 命令中运行一个小的一行程序。

接下来，让我们使用`command`模块:

```
$ ansible -b -k -m command -a 'whoami > BUTTER; cat BUTTER | rev' -i 192.168.33.11, 192.168.33.11
SSH password: 
192.168.33.11 | FAILED | rc=1 >>
whoami: extra operand '>'
Try 'whoami --help' for more information.non-zero return code
```

啊...这失败了。

这是因为`command`没有显式运行一个 shell(比如 Bash)，所以当我们尝试使用>形式的 Bash 主义时，失败了。`command`模块只适用于短命令:

```
$ ansible -b -k -m command -a 'whoami' -i 192.168.33.11, 192.168.33.11
SSH password: 
192.168.33.11 | SUCCESS | rc=0 >>
root
```

# 请参见

在这里，我们使用了一个`SSH`密码在我们的盒子上运行远程命令，但这通常是不做的(尤其是在自动化环境中)。通常使用 SSH 密钥，权限受到严格控制。

# 使用 Ansible 从角色安装 Java

Ansible 非常适合做我们刚刚做的事情，通过在远程机器上使用模块来运行易于理解的命令。

但那不是它的面包和黄油。相反，当对远程机器运行一系列命令，并在几秒钟内进行大量配置更改时，Ansible 确实表现出色。

在本节中，我们将编写一个小的 Ansible Playbook，从公共存储库中导入一个 Ansible 角色，并将该角色应用到我们的 centos2 机器上。

抓住你的帽子！

# 准备好

在本节中，我们再次使用我们的`Vagrantfile`和两个 CentOS 虚拟机。

在完成这一部分之前，最好先完成上一部分。

`SSH`到你的`centos1`机:

```
$ vagrant ssh centos1
```

# 怎么做...

让我们从创建一个目录开始，我们将在其中工作并进入其中:

```
$ mkdir ansible-example
$ cd ansible-example/
```

现在，我们说我们将为此工作使用一个公共的 Ansible 角色，所以让我们搜索一个:

```
$ ansible-galaxy search "java for linux" --author geerlingguy

Found 7 roles matching your search:

 Name Description
 ---- -----------
 geerlingguy.ac-solr Apache Solr container for Docker.
 geerlingguy.elasticsearch Elasticsearch for Linux.
 geerlingguy.java Java for Linux
 geerlingguy.puppet Puppet for Linux.
 geerlingguy.solr Apache Solr for Linux.
 geerlingguy.sonar SonarQube for Linux
 geerlingguy.tomcat6 Tomcat 6 for RHEL/CentOS and Debian/Ubuntu.
```

你也可以使用[https://galaxy.ansible.com/](https://galaxy.ansible.com/)网站:

![](assets/bfcbda58-16c4-4465-bae2-f7b45a14d722.png)

Searching for java on Ansible Galaxy I actually tend to use the website more than the command line, simply because it gives you a good overview of role popularity at a glance. I already knew that the one written by `geerlingguy` was very popular, so I chose to explicitly include his name in the search.

现在我们知道了我们想要使用什么角色，让我们下载它:

```
$ sudo ansible-galaxy install geerlingguy.java
- downloading role 'java', owned by geerlingguy
- downloading role from https://github.com/geerlingguy/ansible-role-java/archive/1.9.4.tar.gz
- extracting geerlingguy.java to /etc/ansible/roles/geerlingguy.java
- geerlingguy.java (1.9.4) was installed successfully
```

太棒了。我们有自己的角色。

现在我们如何应用它？

当然是用剧本！

在您的系统上运行以下程序:

```
$ cat <<HERE > playbook.yml
---
- hosts: all
 roles:
 - geerlingguy.java
HERE
```

现在，运行我们的`playbook`对抗 centos2:

```
$ ansible-playbook -k -b -i 192.168.33.11, playbook.yml
```

您应该会看到一个信息流在您的屏幕上运行，因为我们之前下载的角色应用于远程机器:

![](assets/5e5e3019-191f-40bc-8e21-09d5b32c2b29.png)

Note `ok=6` and `changed=1` at the bottom of the run. If you now run the playbook a second time, you should get `changed=0` since the role is idempotent.

这就是了！只需三个命令(实际上)，您就可以在远程机器上安装一个 Java。

# 它是如何工作的...

通过我们在这一节中所做的，一个命令接一个命令，我们将解释发生了什么。

```
$ ansible-galaxy search "java for linux" --author geerlingguy
```

最初，我们需要知道是否有人已经编写了一个 Ansible 角色来在盒子上安装 Java。碰巧的是，我们能够在输入作者姓名的同时为 Linux 搜索 Java，结果找到了七个角色。

I have a friend who likes to write his own Ansible for a job, but I've always been of the opinion that if a solution already exists (and it's suitable), there's no harm in adopting work that others have written, providing that its license allows you to do so, and your company is fine with it. The open source community is good, and if someone's already invented the wheel, try putting down the hammer and chisel. 

```
$ sudo ansible-galaxy install geerlingguy.java
```

一旦我们知道了我们想要的角色，我们就运行`install`命令。具体来说，我们必须为此使用`sudo`，因为有问题的角色被拉到您的框中，并被放在共享的`/etc/ansible/roles/`目录中，而我们的用户没有对该目录的写访问权限。

通过查看目录，您可以看到这个角色(并根据需要复制或调整它)。

```
$ ls /etc/ansible/roles/geerlingguy.java/
defaults LICENSE meta molecule README.md tasks templates vars
```

实际角色从`tasks/main.yml`开始，所以在里面看一下也是个好主意。

```
$ cat /etc/ansible/roles/geerlingguy.java/tasks/main.yml 
---
- name: Include OS-specific variables for Fedora or FreeBSD.
 include_vars: "{{ ansible_distribution }}.yml"
 when: ansible_distribution == 'FreeBSD' or ansible_distribution == 'Fedora'

- name: Include version-specific variables for CentOS/RHEL.
 include_vars: "RedHat-{{ ansible_distribution_version.split('.')[0] }}.yml"
<SNIP>
```

接下来，我们创建了一个小的`playbook.yml`文件来指定我们应该在哪里安装哪个角色。

```
$ cat <<HERE > playbook.yml
---
- hosts: all
 roles:
 - geerlingguy.java
HERE
```

这里值得注意的是，我们将`hosts`列为`all`，而不是特定的主机名或 IP，角色以 YAML 列表的形式出现。

通过添加不同的变量、不同的角色应用规则以及各种其他选项，您可以将剧本变成一只相当复杂的野兽。

```
$ ansible-playbook -k -b -i 192.168.33.11, playbook.yml
```

最后，我们使用`ansible-playbook`将`playbook.yml`的内容实际应用于`centos2`。我们使用通用选项`-k`、`-b`和`-i`来建立我们的指挥。

现在转到`centos2`，执行`geerlingguy.java`角色的每一行。

# 还有更多...

为了一个角色而编写剧本似乎有些矫枉过正，但剧本的妙处在于它们并不局限于一个角色。您可以在`playbook.yml`文件内的列表中包含任意多个，并且，只要它们彼此不冲突，您就应该拥有非常流畅的 Ansible 体验。

看看这个`playbook.yml`文件吧:

```
$ cat <<HERE > playbook.yml
---
- hosts: all
 roles:
 - geerlingguy.java
 - geerlingguy.docker
 - geerlingguy.apache
HERE
```

我们也用了非常具体的方式`galaxy`，先用`ansible-galaxy`从网上安装角色。您还可以在代码中包含一个`requirements.yml`文件，`ansible-galaxy`可以读取该文件，以便在尝试将列出的角色应用到远程框之前下载找到的任何角色:

```
$ cat <<HERE > playbook-requirements.yml
---
- name: geerlingguy.java
- name: geerlingguy.docker
- name: geerlingguy.apache
HERE
```

然后，在你`playbook`跑之前，你会先跑`galaxy`:

```
$ sudo ansible-galaxy install -r playbook-requirements.yml 
 [WARNING]: - geerlingguy.java (1.9.4) is already installed - use --force to change version to unspecified

- downloading role 'docker', owned by geerlingguy
- downloading role from https://github.com/geerlingguy/ansible-role-docker/archive/2.5.2.tar.gz
- extracting geerlingguy.docker to /etc/ansible/roles/geerlingguy.docker
- geerlingguy.docker (2.5.2) was installed successfully
- downloading role 'apache', owned by geerlingguy
- downloading role from https://github.com/geerlingguy/ansible-role-apache/archive/3.0.3.tar.gz
- extracting geerlingguy.apache to /etc/ansible/roles/geerlingguy.apache
- geerlingguy.apache (3.0.3) was installed successfully
```

这意味着当你运行`ansible-playbook`时，你已经准备好了你的角色:

```
$ ansible-playbook -k -b -i 192.168.33.11, playbook.yml
SSH password: 

PLAY [all] *********************************************************************************************************************************************************************

TASK [Gathering Facts] *********************************************************************************************************************************************************
ok: [192.168.33.11]

<SNIP>

RUNNING HANDLER [geerlingguy.apache : restart apache] **************************************************************************************************************************
changed: [192.168.33.11]

```

```
PLAY RECAP *********************************************************************************************************************************************************************
192.168.33.11 : ok=33 changed=14 unreachable=0 failed=0 
```

# 请参见

正如我在*中提到的如何做...*部分，我已经知道`geerlingguy.java`了，因为作者(`geerlingguy`)在他写的 Ansible 中是多产的。很有可能你会再次看到这个名字，不管你最终为哪个机构工作。

# 用 Git 存储我们的可转换配置

让我们结合到目前为止所学的知识，将我们在上一节中编写的 Ansible 配置存储在我们的 Git 服务器上。

# 准备好

在本节中，我们将主要使用`centos1`，但是我们将把我们的配置上传到`centos2`。

SSH 到您的两个虚拟机:

```
$ vagrant ssh centos1
$ vagrant ssh centos2
```

在 centos2 上，从您的主目录创建另一个空的`Git repository`:

```
$ git init --bare ansible-example.git
Initialized empty Git repository in /home/vagrant/ansible-example.git/
```

# 怎么做...

在`centos1`上，切换到您的`ansible-example`目录:

```
$ cd ansible-example/
```

接下来，将目录初始化为`Git repository`:

```
$ git init
```

将我们已经在目录中的文件`commit`添加到存储库中:

```
$ git add *
$ git commit -m "Adding my playbook files."
```

一旦完成，您的本地存储库是好的，但是我们仍然希望`push`将它们发送到远程目的地。

用别名`origin`添加您的遥控器:

```
$ git remote add origin vagrant@192.168.33.11:ansible-example.git
```

最后，我们可以`push`我们对`remote`存储库的更改:

```
$ git push --set-upstream origin master
vagrant@192.168.33.11's password: 
Counting objects: 4, done.
Compressing objects: 100% (4/4), done.
Writing objects: 100% (4/4), 388 bytes | 0 bytes/s, done.
Total 4 (delta 0), reused 0 (delta 0)
To vagrant@192.168.33.11:ansible-example.git
 * [new branch] master -> master
Branch master set up to track remote branch master from origin.
```

# 它是如何工作的...

我们在这里所做的就是结合我们在最后几节中所做的工作:

*   我们在 centos2 机器上创建了一个 Git 存储库
*   我们采用了自己编写的 Ansible 配置，并围绕它初始化了一个存储库
*   我们把我们的目的地定为中央
*   我们将配置推送到远程机器

现在，即使 centos1 消失了，您在 centos2 上也会有一份配置副本，其他人可以克隆这些信息，进行更改，并向上推送。

There's a reason you traditionally see a  "build server" of some description or other in the land of system administration. This is because you can claim it as a focal point for distribution configuration and managing your infrastructure. It's easy to see how out of sync you could get were five people in a team to work on one project at the same time, each in a different branch, with their own changes.

# 探索 IaC 的选择

在这一部分，我们将从哈希公司的网站下载一些二进制文件，并使用我们的`centos1`虚拟机。

完全自动化您的基础架构超出了本书的范围，但是我们没有理由不讨论目前市场上最流行的几个工具。

Terraform 和 Packer 都是由 Hashicorp 制造的，hashi corp 以让系统管理员的生活变得更容易，或者从不发布他们产品的 1.0.0 版本而闻名，这取决于你问谁。

Hashicorp are also the people who maintain Vagrant, though they did once try to replace it with a program called Otto—we don't talk about Otto.

Terraform 是一种将基础架构编写为声明性代码的方式，有多种提供者可供选择，包括 AWS、Azure、Scaleway、Digital Ocean 等等。

另一方面，Packer 是为您选择的提供商构建基础映像的一种方式，将您认为需要的所有软件全局烘焙到默认映像中，然后您可以使用 Chef、Ansible 或 Puppet 等程序对其进行扩展。

如果您曾经点击过提供商的在线门户网站来配置虚拟机、对象存储或网络，您可能已经理解了 Terraform 和 Packer 听起来令人惊叹的原因。

Neither of these tools were the first to do what they intended to do, but they do them well, and, at the time of writing, they have a vast, vast chunk of the collective mind-share. 

# 准备好

SSH 到`centos1`并下载 Terraform 和 Packer:

```
$ vagrant ssh centos1 $ curl -O https://releases.hashicorp.com/terraform/0.11.10/terraform_0.11.10_linux_amd64.zip
$ curl -O https://releases.hashicorp.com/packer/1.3.2/packer_1.3.2_linux_amd64.zip
```

现在，我们需要解压缩这些二进制文件，所以首先安装适当的工具。然后，解压缩我们的两个应用程序，并将其移动到`/usr/local/bin/`:

```
$ sudo yum install unzip -y
$ unzip packer_1.3.2_linux_amd64.zip 
$ unzip terraform_0.11.10_linux_amd64.zip
$ sudo mv terraform /usr/local/bin/
$ sudo mv packer /usr/local/bin/
```

Terraform and Packer evolve so quickly that remarkably few repositories will actually have them. The programs also complain if you use a version that's out of date, displaying a large banner every time you use them. The only repository I've come across that seems to consistently package Terraform is the FreeBSD default repo (and even that's out of date).

我们还将为此使用`docker`，因此如果您的虚拟机上没有安装它，请运行以下命令(这在本书前面有更详细的介绍):

```
$ sudo yum install yum-utils -y
$ sudo yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo
$ sudo yum install docker-ce -y
$ sudo systemctl enable --now docker
```

# 怎么做...

我们将依次检查我们的两个程序。

# 将（行星）地球化（以适合人类居住）

从顶部开始，我们将使用 Terraform 在本地创建一个小型 Docker 部署。这是最容易展示的，因为我们的虚拟机上有我们需要的所有工具，这并不意味着我必须告诉您出去并在某个云提供商上开始免费试用。

首先为我们创建一个工作目录:

```
$ mkdir example-terraform
$ cd example-terraform
```

接下来，将以下配置插入`main.tf`文件:

```
$ cat <<HERE > main.tf
provider "docker" {
 host = "unix:///var/run/docker.sock"
}

resource "docker_image" "example-image" {
 name = "nginx"
}

resource "docker_container" "example-container" {
 name = "nginx-example"
 image = "\${docker_image.example-image.latest}"
}
HERE
```

然后，初始化地形:

```
$ sudo /usr/local/bin/terraform init

Initializing provider plugins...

The following providers do not have any version constraints in configuration,
so the latest version was installed.

To prevent automatic upgrades to new major versions that may contain breaking
changes, it is recommended to add version = "..." constraints to the
corresponding provider blocks in configuration, with the constraint strings
suggested below.

* provider.docker: version = "~> 1.1"

Terraform has been successfully initialized!

You may now begin working with Terraform. Try running "terraform plan" to see
any changes that are required for your infrastructure. All Terraform commands
should now work.

If you ever set or change modules or backend configuration for Terraform,
rerun this command to reinitialize your working directory. If you forget, other
commands will detect it and remind you to do so if necessary.
```

We're using `sudo` here because our user isn't in the group that can control Docker and, as a result, Terraform won't be able to talk to Docker either when invoked by us.

一旦初始化，您现在应该能够应用我们的配置。

先看`docker ps`:

```
$ sudo docker ps
CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES
```

然后，运行`terraform apply`:

```
$ sudo /usr/local/bin/terraform apply

An execution plan has been generated and is shown below.
Resource actions are indicated with the following symbols:
 + create

Terraform will perform the following actions:

 + docker_container.example-container
 id: <computed>
 attach: "false"
 bridge: <computed>
 container_logs: <computed>
 exit_code: <computed>
 gateway: <computed>
 image: "${docker_image.example-image.latest}"
 ip_address: <computed>
 ip_prefix_length: <computed>
 log_driver: "json-file"
 logs: "false"
 must_run: "true"
 name: "nginx-example"
 network_data.#: <computed>
 restart: "no"
 rm: "false"
 start: "true"

 + docker_image.example-image
 id: <computed>
 latest: <computed>
 name: "nginx"

Plan: 2 to add, 0 to change, 0 to destroy.

Do you want to perform these actions?
 Terraform will perform the actions described above.
 Only 'yes' will be accepted to approve.

 Enter a value: 
```

您应该会看到将要采取的操作的详细信息，以及让您键入`yes`的提示。这样做并点击*进入*:

```
 Enter a value: yes

docker_image.example-image: Creating...
 latest: "" => "<computed>"
 name: "" => "nginx"
docker_image.example-image: Still creating... (10s elapsed)
docker_image.example-image: Creation complete after 18s (ID: sha256:568c4670fa800978e08e4a51132b995a54f8d5ae83ca133ef5546d092b864acfnginx)
docker_container.example-container: Creating...
 attach: "" => "false"
 bridge: "" => "<computed>"
 container_logs: "" => "<computed>"
 exit_code: "" => "<computed>"
 gateway: "" => "<computed>"
 image: "" => "sha256:568c4670fa800978e08e4a51132b995a54f8d5ae83ca133ef5546d092b864acf"
 ip_address: "" => "<computed>"
 ip_prefix_length: "" => "<computed>"
 log_driver: "" => "json-file"
 logs: "" => "false"
 must_run: "" => "true"
 name: "" => "nginx-example"
 network_data.#: "" => "<computed>"
 restart: "" => "no"
 rm: "" => "false"
 start: "" => "true"
docker_container.example-container: Creation complete after 0s (ID: 4f462e164239c65605c9106378ffb260b8bb7f5d27dc1fe0e008589a1387650e)

Apply complete! Resources: 2 added, 0 changed, 0 destroyed.
```

太棒了！

再次运行`docker ps`查看您刚刚创建的内容:

```
$ sudo docker ps
CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES
4f462e164239 568c4670fa80 "nginx -g 'daemon of..." 28 seconds ago Up 26 seconds 80/tcp nginx-example
```

现在，让我们`destroy`我们的容器，再次使用地形:

```
$ sudo /usr/local/bin/terraform destroy
docker_image.example-image: Refreshing state... (ID: sha256:568c4670fa800978e08e4a51132b995a54f8d5ae83ca133ef5546d092b864acfnginx)
docker_container.example-container: Refreshing state... (ID: 4f462e164239c65605c9106378ffb260b8bb7f5d27dc1fe0e008589a1387650e)

An execution plan has been generated and is shown below.
Resource actions are indicated with the following symbols:
 - destroy

Terraform will perform the following actions:

 - docker_container.example-container

 - docker_image.example-image

Plan: 0 to add, 0 to change, 2 to destroy.

Do you really want to destroy all resources?
 Terraform will destroy all your managed infrastructure, as shown above.
 There is no undo. Only 'yes' will be accepted to confirm.

 Enter a value: 
```

再次提示我们在提供的字段中输入`yes`。这样做并点击*进入:*

```
 Enter a value: yes

docker_container.example-container: Destroying... (ID: 4f462e164239c65605c9106378ffb260b8bb7f5d27dc1fe0e008589a1387650e)
docker_container.example-container: Destruction complete after 0s
docker_image.example-image: Destroying... (ID: sha256:568c4670fa800978e08e4a51132b995a54f8d5ae83ca133ef5546d092b864acfnginx)
docker_image.example-image: Destruction complete after 0s

Destroy complete! Resources: 2 destroyed.
```

轰！我们的集装箱不见了。

# 包装工人

假设我们不想只使用 Docker Hub 中的容器。假设我们想在使用 Terraform 部署它之前稍微调整一下。

这就是 Packer 的用武之地，它是一个非常通用的工具。Packer 有 AWS、Scaleway、LXC、VirtualBox、QEMU 等的构建器，但我们感兴趣的是 Docker。

回到你的主目录，创建一个`example-packer`目录:

```
$ cd ~
$ mkdir example-packer
$ cd example-packer
```

接下来，将以下内容输出到文件中:

```
$ cat <<HERE > docker.json
{ 

 "builders":[
 {
 "type": "docker",
 "image": "nginx",
 "commit": true,
 "pull": true,
 "changes": [
 "LABEL custom=true",
 "EXPOSE 443"
 ]
 }],

 "provisioners":[
 {
 "type": "shell",
 "inline": ["echo 'Bring back Black Books!'","apt remove nginx -y"]
 }]

} 
HERE
```

一旦完成，您应该能够运行`packer`到`build`并调整您的容器:

```
$ sudo /usr/local/bin/packer build docker.json
docker output will be in this color.

==> docker: Creating a temporary directory for sharing data...
==> docker: Pulling Docker image: nginx
 docker: Using default tag: latest
 docker: latest: Pulling from library/nginx
 docker: Digest: sha256:5d32f60db294b5deb55d078cd4feb410ad88e6fe77500c87d3970eca97f54dba
 docker: Status: Image is up to date for nginx:latest
==> docker: Starting docker container...
 docker: Run command: docker run -v /root/.packer.d/tmp/packer-docker860052889:/packer-files -d -i -t nginx /bin/bash
 docker: Container ID: 2047e58a479904968bff162d279ac42d1e162878fb6b8e2176bb3e4551669c17
==> docker: Using docker communicator to connect: 172.17.0.2
==> docker: Provisioning with shell script: /tmp/packer-shell763812364
 docker:
 docker: WARNING: apt does not have a stable CLI interface. Use with caution in scripts.
 docker: Bring back Black Books!
 docker:
 docker: Reading package lists...
 docker: Building dependency tree...
 docker: Reading state information...
 docker: The following packages were automatically installed and are no longer required:
 docker: fontconfig-config fonts-dejavu-core libbsd0 libedit2 libexpat1
 docker: libfontconfig1 libfreetype6 libgd3 libgeoip1 libicu57 libjbig0
 docker: libjpeg62-turbo libpng16-16 libssl1.1 libtiff5 libwebp6 libx11-6 libx11-data
 docker: libxau6 libxcb1 libxdmcp6 libxml2 libxpm4 libxslt1.1 ucf
 docker: Use 'apt autoremove' to remove them.
 docker: The following packages will be REMOVED:
 docker: nginx nginx-module-geoip nginx-module-image-filter nginx-module-njs
 docker: nginx-module-xslt
 docker: 0 upgraded, 0 newly installed, 5 to remove and 0 not upgraded.
 docker: After this operation, 5336 kB disk space will be freed.
 docker: (Reading database ... 7026 files and directories currently installed.)
 docker: Removing nginx-module-njs (1.15.7.0.2.6-1~stretch) ...
 docker: Removing nginx-module-xslt (1.15.7-1~stretch) ...
 docker: Removing nginx-module-geoip (1.15.7-1~stretch) ...
 docker: Removing nginx-module-image-filter (1.15.7-1~stretch) ...
 docker: Removing nginx (1.15.7-1~stretch) ...
 docker: invoke-rc.d: could not determine current runlevel
 docker: invoke-rc.d: policy-rc.d denied execution of stop.
==> docker: Committing the container
 docker: Image ID: sha256:53a34cbb093015f423de89ad874afebb3b9470f3750e858729f75ed8e3f4bce4
==> docker: Killing the container: 2047e58a479904968bff162d279ac42d1e162878fb6b8e2176bb3e4551669c17
Build 'docker' finished.

==> Builds finished. The artifacts of successful builds are:
--> docker: Imported Docker image: sha256:53a34cbb093015f423de89ad874afebb3b9470f3750e858729f75ed8e3f4bce4
```

太好了。我们现在有了一个可以在其他地方使用的图像:

```
$ sudo docker image ls
REPOSITORY TAG IMAGE ID CREATED SIZE
<none> <none> 53a34cbb0930 19 seconds ago 110MB
nginx latest 568c4670fa80 19 hours ago 109MB
alpine latest 196d12cf6ab1 2 months ago 4.41MB
```

# 它是如何工作的...

让我们把它分解一下，从地形开始。

在本节中，我们通过将配置写入一个`main.tf`文件来定义我们希望我们的基础架构是什么样子:

```
provider "docker" {
  host = "unix:///var/run/docker.sock"
}

resource "docker_image" "example-image" {
  name = "nginx"
}

resource "docker_container" "example-container" {
  name = "nginx-example"
  image = "${docker_image.example-image.latest}"
}
```

具体来说，我们在这里所做的是为 Terraform 提供它的提供者以及与所述提供者连接的必要信息(在本例中，是一个 Unix 套接字):

```
provider "docker" {
  host = "unix:///var/run/docker.sock"
}
```

然后，我们通知 Terraform 我们想要用作容器基础的图像:

```
resource "docker_image" "example-image" {
  name = "nginx"
}
```

最后，我们要说的是容器应该被称为`nginx-example`，它应该使用我们之前定义的图像(注意前面块的引用变量的使用):

```
resource "docker_container" "example-container" {
  name = "nginx-example"
  image = "${docker_image.example-image.latest}"
}
```

保存后，我们运行了一个命令来初始化 Terraform 使用的目录:

```
$ sudo /usr/local/bin/terraform init
```

这将下载提供程序(docker)并设置目录供我们使用。然后，我们应用了我们的配置:

```
$ sudo /usr/local/bin/terraform apply
```

Terraform 在其调用的目录中查找任何以`.tf`结尾的文件。

之后，我们摧毁了我们的装置:

```
$ sudo /usr/local/bin/terraform destroy
```

您的目录最终会如下所示:

```
$ ls -lha
total 16K
drwxrwxr-x. 3 vagrant vagrant 96 Nov 28 17:05 .
drwx------. 9 vagrant vagrant 4.0K Nov 28 17:07 ..
-rw-rw-r--. 1 vagrant vagrant 251 Nov 28 17:02 main.tf
drwxr-xr-x. 3 root root 21 Nov 28 17:02 .terraform
-rw-r--r--. 1 root root 318 Nov 28 17:05 terraform.tfstate
-rw-r--r--. 1 root root 2.9K Nov 28 17:05 terraform.tfstate.backup
```

注意`state`文件。这一点很重要，因为它包含您所配置的基础架构的已知状态。往里看，你会看到一个类似 JSON 的语法，尽管这可能会改变。地形状态文件不应该手工修改。

I have horror stories revolving around having to manually recover the state of infrastructure, as I'm sure many others do too, and believe me when I tell you that losing a state file is not fun, nor is it going to be a quick recovery process. Needless to say, it's a good idea to keep this file backed up.

还值得注意的是，您可以将 Terraform 状态文件存储在远程位置。这可以配置为在使用时“锁定”(以避免两个用户试图同时访问状态文件时发生冲突的更改。)这也意味着状态文件不存在于您的本地机器上，或者詹金斯从机上，这使得分布式构建更加容易。

前面的`terraform`目录包含了我们初始化存储库时下载的实际插件。

去帕克！

有了 Packer，事情就有点不一样了。首先，我们设置这个配置文件:

```
{ 

  "builders":[
  {
    "type": "docker",
    "image": "nginx",
    "commit": true,
    "pull": true,
    "changes": [
      "LABEL custom=true",
      "EXPOSE 443"
    ]
  }],

  "provisioners":[
  {
    "type": "shell",
    "inline": ["echo 'Bring back Black Books!'","apt remove nginx -y"]
  }]

}
```

这是一个非常普通的例子，但它达到了它的目的。

您可能注意到的第一件事是它是 JSON 格式的，而不是使用 HCL(terra form 对其配置就是这样)。其次，您可能会注意到，虽然我们配置了一个构建器(docker)，但我们也有一个置备器(shell)。

```
  "builders":[
  {
    "type": "docker",
    "image": "nginx",
    "commit": true,
    "pull": true,
    "changes": [
      "LABEL custom=true",
      "EXPOSE 443"
    ]
  }],
```

从构建器开始，您可以看到我们使用`docker`作为类型，以便 Packer 知道这是什么构建器，并且我们还使用我们之前使用的`nginx`图像作为基础。

我们以标签的形式应用一些元数据更改，并将不同的端口暴露给图像中的默认端口(80)。我们可以在生成的 Docker 图像中看到这些:

```
$ sudo docker inspect 53a34cbb0930 | grep "custom\|443"
 "443/tcp": {},
 "custom": "true",
```

接下来，我们进入打包器作业的核心，即供应步骤:

```
  "provisioners":[
  {
    "type": "shell",
    "inline": ["echo 'Bring back Black Books!'","apt remove nginx -y"]
  }]
```

这就是你要对容器进行更改的部分，比如这里，我们用`shell`对`echo`对屏幕做了一个尖锐的声明，然后激进地移除了容器的唯一目的以示抗议。

Packer has other provisioners, such as Ansible, Chef, and Puppet, but `shell` is the easiest to understand and implement. 

最后，我们建立了自己的形象:

```
$ sudo /usr/local/bin/packer build docker.json
```

Packer 从 Docker Hub 中提取指定的图像，然后对元数据和内容进行我们指定的更改，最后打包图像并将其存储在本地。

我们也可以引入一个后处理器步骤，以不同的方式标记和上传我们的新图像到某个安全的地方。

# 还有更多...

这里有一个小而有趣的小故事。Terraform 有一个内置命令，用于确保您的所有语法都被很好地格式化(这意味着每个人都可以遵守相同的标准，而不会陷入关于间距的愚蠢争论):

```
$ terraform fmt
main.tf
```

老实说，我认为这是 Terraform 最伟大的地方之一，因为这意味着没有人能有自己的看法，如果有一个我想生活的世界，那就是那个世界。

# 请参见

哈希公司制造了很多东西，虽然重要的是要记住，当谈到基础设施作为代码时，有几种选择，但不可否认的是，目前，如果你很了解他们的套件，你将会大大增加你找到工作的机会。

哈希公司的其他工具包括:

*   流浪，正如我们所知和所爱
*   金库，用于秘密储存
*   服务发现顾问

# 综述- Git、配置管理和基础设施作为代码

这不是一本关于 Ansible 的书，虽然我很想写一本，但已经有相当多的书了(尽管说实话，Ansible 节奏太快了，你最好边走边学，我通常不提倡这样做)。也就是说，我确实喜欢 Ansible，并且，连同本章中列出的其他工具(Git、Terraform、Packer)，在过去的几年里，它让我的生活变得更加轻松，以至于我一直在使用它。

对于管理员懒惰的想法，我们有话要说，因为我们真正想做的是通过自动化消除繁琐的部分，让我们的工作变得更容易。我们都曾开玩笑说，有一天我们会自动失业，但我们家族中一些不太懒惰的人不喜欢这个想法，似乎决定他们几乎每月都要开发一个新东西，这样我们就可以拿起这个东西，并决定我们迫切需要在我们的基础设施中使用它。

Git 是神奇的，它让我们对源代码控制和分发的需求变得无缝(除非你忘记了如何从自己陷入的混乱中恢复过来，并决定删除目录并再次克隆它更容易)。

Ansible 是一个救星，这意味着我们不再需要在凌晨打电话给退休已久的老大爷，就为了找出他们是如何设法让那台旧雪花服务器的一半在内存中运行的，而其余的似乎是从网络驱动器中拉进来的。

Don't assume that just because somewhere uses Ansible, and they claim to be fully automated, that they don't have one server kicking around somewhere that no one wants to touch because it does something silly like handle the IVR for the phone server. In these cases, you can do one of two things. Either option A: offer to automate the old and crusty snowflake, bringing it in line with the rest of the infrastructure; or option B: stick your head in the sand like everyone else, and hope it doesn't break while you're on shift (though it will... it will...).

Terraform 在代码形式上是一个令人头疼的问题，尽管用户偶尔会对它感到不满，但不可否认的是，在一个面向云的世界里，拥有一个可以在 Azure 订阅中自动提供数百个盒子的工具是必须的，如果这意味着你不必学习 PowerShell——那就更好了。不过，值得一提的是，我有一个朋友坚持认为 Terraform 还没有准备好，因此他以一个可翻译的角色包装了 Terraform 文件的生成...别问了。

Packer 消除了沉闷，并确保您的 Ansible 行动手册不会因为您做了明智的事情并将所有明智的默认设置合并到一个基本图像中而花时间应用(提示，提示！).

为了结束这一章，我们来谈谈云的时代。

我们提到的所有工具在一个短暂的世界里都很棒，在这个世界里，服务器可以旋转几分钟，完成它们在生活中的目的，然后被一个无所不能的 cronjob 毫不客气地从存在中移除。不过，它们也有缺点，使用 Terraform 等工具管理房产时一定要小心。

Terraform 在让您删除基础架构之前，会以有效的“您真的确定”消息提示您，这是有原因的。我总是建议在你做之前，对你将要做的事情百分之百的自信。你不想成为破坏生产的人(确保你有好的备份)。

在过去，当我不小心关闭了一个服务器，因为我把它和一个类似名称的不同服务器混淆了，它在任何人注意到之前关闭了 12 个小时，这种影响是最小的。我可以简单地打开盒子，同时向客户道歉。

现在，如果您不小心对 prod 运行了`terraform destroy`，并且它还带走了数据，那么您所做的不仅仅是将盒子翻转。他们走了，卡普特，阿瓦达·凯达拉，所以要小心。我们有这些工具让我们的生活变得更容易，但有时我想知道我们是否也给了自己更多的意外毁灭的能力。

That story about me turning off a box may or may not be true......it's true.