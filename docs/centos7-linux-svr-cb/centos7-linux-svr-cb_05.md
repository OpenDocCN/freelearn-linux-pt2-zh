# 第五章：管理文件系统

在本章中，我们将涵盖以下主题：

+   创建虚拟块设备

+   格式化和挂载文件系统

+   使用磁盘配额

+   维护文件系统

+   扩展文件系统的容量

# 简介

本章是一系列步骤的集合，旨在满足驱动基于 CentOS 的服务器解决方案的需求。从格式化和挂载磁盘到扩展逻辑卷以及维护文件系统和磁盘配额，本章的目的是向你展示如何快速轻松地掌握管理当今最苛刻环境中用户需求任务的技能。

# 创建虚拟块设备

在本步骤中，我们将创建一个虚拟块设备，用于模拟真实设备和分区，以便我们可以在本章后续的所有步骤中测试驱动概念和命令。使用真实磁盘和分区通常涉及丢失重要数据甚至需要重新安装整个系统的风险。虚拟块设备是学习技术和尝试操作的理想选择，然后再切换到“生产模式”。稍后，如果你获得了足够的经验并感到安全，你可以轻松地将其替换为“真实”硬件设备、分区以及逻辑卷（这是 LVM 的一部分；请参阅后面的步骤）。你所需要做的就是将你的虚拟设备替换为“真实”块设备名称。

## 准备工作

要完成这个步骤，你需要一个具有 root 访问权限的 CentOS 7 操作系统的最小安装。为了创建一个虚拟块设备，你应该至少有一 GB 的可用硬盘空间，我们将暂时使用这些空间来创建和制作。你可以在之后删除这部分预留空间（或者在重启后它会自动删除）。这只是为了测试。

## 如何操作...

1.  首先，以`root`身份登录并创建一个精确大小为 1GB 的空文件：

    ```
    dd if=/dev/zero of=/tmp/test-image.dd bs=1M count=1000

    ```

1.  现在，让我们从刚刚创建的文件中创建一个循环设备：

    ```
    losetup -fP  /tmp/test-image.dd

    ```

1.  接下来，打印生成的循环设备名称：

    ```
    losetup -a

    ```

1.  由于这将是当前系统中创建的第一个循环设备，输出将如下所示（如果你之前创建了循环设备，`loop0`可能是一个不同的数字）：

    ```
    /dev/loop0: [0035]:3714186 (/tmp/test-image.dd)

    ```

1.  要获取当前系统上所有已附加的块设备的列表以及重要详细信息，请键入以下内容：

    ```
    lsblk -io NAME,TYPE,SIZE,MOUNTPOINT,FSTYPE,MODEL

    ```

1.  现在，让我们在我们的新循环设备上创建一个类型为`gpt`的新分区表（确认删除任何数据）：

    ```
    parted /dev/loop0 mklabel gpt

    ```

1.  最后，从你的循环设备创建设备映射，使其更类似于真实的硬盘分区：

    ```
    kpartx -a /dev/loop0

    ```

## 它是如何工作的...

在本步骤中，我们学习了如何创建一个虚拟块设备，作为测试如何在本章后续步骤中创建分区、逻辑卷和文件系统的起点。

那么，我们从这次经历中学到了什么？

我们通过使用`dd`工具在`/tmp`目录中创建一个大小为 1GB 的新空文件来开始这个操作。`dd`用于制作文件的精确副本（有时称为克隆），并期望两个参数：输入文件（`if`参数）和输出文件（`of`参数）。我们使用`zero`设备（`/dev/zero`）作为输入文件，它返回一个包含零的无尽字节流。然后，我们通过定义块大小（`bs`）和`count`参数来限制流。`bs`定义了一次读取的数据量（以字节为单位），而`count`参数计算`bs`将允许重复多少次。因此，这些参数可以被理解为*当达到块大小乘以计数的数据量时停止复制过程*。在我们的示例中，我们使用了`1`*兆字节乘以 1000 = 1GB*的块大小。这些零字节数据被写入到我们的输出文件（`of`），称为`/tmp/test-image.dd`。

在我们创建了这个空文件之后，我们用它创建了一个临时的**循环**设备。循环设备只是一个伪设备，它使得可以将文件用作**块设备**。通常，这样的文件是一个 CD ISO 镜像，将其用作循环设备将使其可访问，就像它是一个正常的硬件驱动器一样。任何允许以块为单位读写数据的设备都可以称为块设备；为了获取系统中所有可用块设备的列表，我们使用了`lsblk`命令，正如您所见，这也包括我们的循环设备。标准的循环设备名称以数字零开头，例如`/dev/loop0`。

之后，我们使用`parted`命令在我们的循环设备上创建了一个新的**分区表**。分区表是操作系统在磁盘上维护的一个表，描述了磁盘上的分区，我们必须先创建分区表，然后才能创建分区。我们使用了分区表类型`gpt`，但您也可以在这里使用旧的 msdos 类型。

通常，在虚拟块设备上创建分区表时，我们无法访问单个分区或为其上的不同分区创建文件系统，因为分区不能单独寻址。在这里，我们使用`kpartx`命令从分区表创建设备映射，这允许我们稍后使用表示法`/dev/loop0p1`访问循环设备 0 上的分区 1，以及`/dev/loop0p2`访问循环设备 0 上的分区 2，以便为单个分区创建文件系统。

恭喜，您现在已经创建了一个带有标准分区表的新虚拟块设备，它可以像普通磁盘设备一样被使用和访问。

## 还有更多...

如果我们想要移除一个虚拟块设备，首先需要将其从文件系统中卸载，如果它当前已挂载（例如，`umount /dev/loop0p1`）。接下来，我们需要使用`-d`参数将虚拟块设备文件从循环设备中分离，如下所示：`losetup -d /dev/loop0`。之后，如果我们愿意，可以删除块文件：`rm /tmp/test-image.dd`。

# 格式化和挂载文件系统

在本食谱中，您将了解标准 CentOS 文件系统**XFS**、**Ext4**和**Btrfs**。文件系统是任何操作系统最基本的部分之一，几乎所有东西都依赖于它们。在这里，您将学习如何在 CentOS 7 中创建不同类型的标准文件系统，以及如何将它们链接到您的系统，以便我们随后可以访问它们进行读写。这两种技术被称为**格式化**和**挂载**文件系统；虽然您不经常这样做，但它仍然是 Linux 系统管理员最基本的任务之一。

## 准备就绪

要完成此食谱，您需要具备具有 root 访问权限的 CentOS 7 操作系统的最小安装。我们还将使用虚拟块设备而不是实际磁盘设备，因为使用“虚拟”设备演示创建文件系统和格式化磁盘的使用情况比擦除实际硬盘内容更好。因此，您应该已经应用了*创建虚拟块设备*食谱，并创建了一个 1GB 的虚拟块设备，在本例中将被命名为`/dev/loop0`。

如果您想将此方法应用于实际磁盘设备，您只需将`/dev/loop0`替换为正确的分区——例如，对于逻辑卷（lv），如`/dev/mapper/myServer/data`，对于 SATA 设备，如`/dev/sdX`，或对于基于 IDE 的硬盘名称，如`/dev/hdX`（其中`X`是字符`a-z`）。

## 如何操作...

在我们的示例中，此块设备被标记为`/dev/loop0`。请注意，如果您创建了多个块设备，您的编号可能会有所不同，因此请相应地更改名称：

1.  首先，让我们以`root`身份登录并显示所有当前可用的块设备的信息：

    ```
    lsblk -io NAME,TYPE,SIZE,MOUNTPOINT,FSTYPE,MODEL

    ```

1.  现在，重新检查我们是否在设备上安装了有效的分区表：

    ```
    parted /dev/loop0 print

    ```

1.  前面的行应该打印出以下内容：`Partition Table: gpt`。如果不是这种情况，让我们创建一个新的分区表（确认删除任何数据）：

    ```
    parted /dev/loop0 mklabel gpt

    ```

1.  现在，我们将创建一个覆盖整个磁盘空间的新分区，并使用`ext4`文件系统标签（尚未安装文件系统；它只是一个标签）：

    ```
    parted -a optimal /dev/loop0 mkpart primary ext4 2048KiB 100%

    ```

1.  再次打印分区表以显示我们刚刚创建的新分区：

    ```
    parted /dev/loop0 print

    ```

1.  现在，让我们删除分区：

    ```
    parted /dev/loop0 rm 1

    ```

1.  我们还可以创建一个带有 btrfs 标签的分区：

    ```
    parted -a optimal /dev/loop0 unit MB mkpart primary btrfs 2048KiB 100%

    ```

1.  之后，让我们创建一个覆盖整个磁盘的 XFS 标签分区：

    ```
    parted /dev/loop0 rm 1
    parted -a optimal /dev/loop0 mkpart primary xfs 2048KiB 100%

    ```

1.  现在，再次显示块表以查看我们更改了什么：

    ```
    lsblk -io NAME,TYPE,SIZE,MOUNTPOINT,FSTYPE,MODEL

    ```

1.  由于我们只定义了分区类型*标签*，我们仍然没有在分区上安装有效的文件系统；因此，在下一步中，我们使用正确的类型格式化磁盘。在我们的示例中，我们使用 XFS。请根据需要更改`mkfs -t <type>`，如果您使用`ext4`或`btrfs`：

    ```
    mkfs -t xfs /dev/loop0p1

    ```

1.  接下来，让我们将虚拟块设备分区挂载到系统上，挂载到目录`/media/vbd-1`，并请根据需要更改`-t <type>`，如果您使用`ext4`或`btrfs`：

    ```
    mkdir /media/vbd-1
    mount -t xfs /dev/loop0p1  /media/vbd-1

    ```

1.  最后，测试我们是否可以对新文件系统进行读写：

    ```
    echo "this is a test" > /media/vbd-1/testfile.txt
    cat /media/vbd-1/testfile.txt

    ```

## 它是如何工作的…

在这个过程中，我们向用户展示了如何创建 CentOS 7 标准分区，覆盖整个磁盘，然后我们在这些分区上创建了一些文件系统，这称为格式化，使用了不同的文件系统类型。CentOS 7 中的标准文件系统是 XFS，但正如我们在本过程中所学到的，还有许多其他可用的文件系统，包括流行的 ext4 和 btrfs。XFS 是一种非常健壮且高性能的文件系统，适用于大型存储配置；它被认为非常成熟和稳定。在 CentOS 7 之前，标准文件系统是 ext4，但它有一些限制，并且在处理数百万个文件时性能不佳，被认为勉强适合当今非常大的文件系统。btrfs 是一个相对较新的文件系统，包含在 CentOS 7 中，但在撰写本文时仍处于开发阶段，不应在生产系统中使用。预计在后续的 CentOS 7 小版本中将得到全面支持，并有可能在未来取代 XFS 成为 CentOS 的标准文件系统类型，因为它具有一系列非常有前景的特性和增强功能，例如写时复制，每次写入文件时都会复制文件，这使得能够回溯到以前的文件版本。

那么，我们从这次经历中学到了什么？

我们通过使用`lsblk`命令开始这个过程，该命令用于打印系统上当前连接的所有可用块设备的列表。我们使用这个命令来检查我们想要用于安装分区和文件系统的目标块设备是否可用。在我们的例子中，我们将使用`/dev/loop0`设备，如果您的系统上名称不同，请更改此名称（如前所述，您也可以使用“真实”磁盘块设备，例如`/dev/sda`，但始终要小心！）。确认设备准备就绪后，我们使用`parted`命令检查磁盘的分区表。分区表对于任何硬盘都是必需的，以便跟踪其上的分区信息。如您所见，我们创建分区表和分区的首选工具是*parted*，因为它是 CentOS 7 官方推荐的工具，但也有其他程序可以执行相同任务，例如`fdisk`或`gdisk`。如果没有可用的分区表，我们必须使用 parted 的`mklabel gpt`参数创建一个类型为`gpt`的分区表。

接下来，在我们创建了分区表之后，我们在其上放置了一些分区。因此，我们使用 parted 的`mkpart`命令，并带有`-a optimal primary ext4 2048KiB 100%`选项。

### 注意

始终小心使用`parted`命令，并在执行前仔细检查所有内容，因为其大多数命令都会彻底销毁磁盘上当前存储的所有数据。

这将创建一个新的分区，从 2,048 千字节（kb）开始直到磁盘末端。我们没有从磁盘的最开始（0%）开始，因为 2,048 kb 是磁盘上第一个扇区的开始，留下一些空间来存储一些额外的数据。`-a optimal`将分区对齐到物理块大小的倍数，这将保证最佳性能。接下来，我们使用`rm`选项和数字`1`删除了分区，这指的是我们刚刚创建的第一个分区。我们重新创建了类型为`btrfs`和最终`xfs`的新分区。在磁盘分区之后，我们需要在其上创建一个实际的文件系统，因为 parted 仅将分区标记为特定类型，但并不进行实际的格式化。为了创建文件系统，我们使用`mkfs`工具。你可以使用`-t`标志运行它，就像我们所做的那样，或者使用点表示法，例如`mkfs.xfs`，来指定你想要格式化的类型。`mkfs`命令为我们提供了详细的输出，例如已经写入了多少块等等。

最后，在我们为磁盘分区创建了文件系统之后，我们可以使用`mount`命令使其可用并在当前系统中工作。`mount`要么将设备的文件系统附加到我们系统的根文件系统，要么将其分离。因此，我们需要首先创建一个目录来定义我们想要将其附加到哪里。我们使用目录`/media/vbd-1`作为实际`mount`命令的参数，语法为`mount -t <文件系统类型> <设备> <目录>`。对于几乎所有标准文件系统，你可以跳过`-t`参数，因为它会自动检测正确的类型。要从系统中分离文件系统，你可以使用`umount`命令，参数是你想要移除的设备（你也可以使用它所挂载的文件夹；两者都有效！）。在我们的例子中，要卸载我们的循环设备的第一分区，请输入`umount /dev/loop0p1`。

在挂载我们格式化的分区设备之后，我们可以像访问根目录下的任何其他组件一样访问它。

## 还有更多...

在本食谱中，我们总是使用一个分区覆盖整个可用磁盘空间。通常，你会在一个磁盘上有多个分区，所以让我们创建这种布局。在这个例子中，我们在`/dev/loop0`上创建三个 100 MB 的分区：

1.  首先，让我们再次使用`rm`参数删除我们的分区，以便我们可以添加新的分区：

    ```
    parted /dev/loop0 rm 1

    ```

1.  现在，让我们创建三个等分的分区：

    ```
    parted -a optimal /dev/loop0 unit MiB mkpart primary ext4 2048KiB 100
    parted -a optimal /dev/loop0 unit MiB mkpart primary ext4 100 200
    parted -a optimal /dev/loop0 unit MiB mkpart primary ext4 300 400

    ```

1.  让我们回顾一下我们的布局：

    ```
    parted /dev/loop0 print

    ```

    ### 注意

    使用`gpt`分区表，我们可以在任何磁盘上创建多达 128 个主分区；当使用较旧的`msdos`分区类型时，最多有四个主分区。如果你需要更多，你必须从主分区中创建扩展分区。

# 使用磁盘配额

在管理具有多个系统用户的 Linux 多用户系统时，明智的做法是设置某种限制或限制系统共享资源的限制。在文件系统级别，您可以限制可用硬盘空间或总文件数到固定大小，可以是用户、组或目录级别。引入这些规则可以防止人们“滥发”系统，填满其可用空间，并且通常您的用户将更加意识到重要和不重要数据之间的区别，并且更有可能保持其主目录整洁和干净。在本食谱中，我们将向您展示如何为 XFS 文件系统设置**磁盘配额**限制系统，该系统对系统用户帐户允许存储的数据量施加限制。

## 准备就绪

要完成本食谱，您需要具有 root 访问权限的 CentOS 7 操作系统的最小安装和您选择的基于控制台的文本编辑器。为了使本食谱工作，并且为了设置配额，您至少需要一个系统用户帐户，除了您的 root 帐户；如果您还没有一个，请参阅第三章，*管理用户和他们的组*，了解如何创建一个。此外，在本食谱的主要部分中，假设您的 CentOS 7 使用 XFS 文件系统，这是安装时的标准。最后，您的 CentOS 7 安装需要安装在至少 64 GB 空间的磁盘上，否则安装程序不会创建单独的逻辑`/home`卷，这是本食谱中使配额工作的要求。

## 如何做到这一点...

在这里，我们将学习如何为 XFS 文件系统设置配额系统的两种不同方式：首先，设置用户和组的限制，然后设置目录（项目）级别的限制。磁盘配额系统必须在文件系统挂载时设置。

### 启用用户和组配额

1.  首先，以`root`身份登录并打开包含静态挂载信息的`fstab`文件：

    ```
    vi /etc/fstab

    ```

1.  现在，将光标导航到包含`/home`的行（使用*上*和*下*箭头键），并将其移动到单词`defaults`，然后在`defaults`之后添加以下文本，用逗号分隔：

    ```
    ,uquota,gquota

    ```

1.  完整的行将如下所示（您的设备名称将根据您的个人 LVM 名称而不同；在这里，它是`myserver`）：

    ```
    /dev/mapper/myserver-home /home  XFS    defaults,uquota,gquota 0 0

    ```

1.  保存并关闭文件，然后重新挂载`/home`分区以激活`quota`指令：

    ```
    umount /home;mount -a

    ```

1.  接下来，为特定用户名为`john`的用户（根据您系统上可用的用户进行适当更改）创建用户配额，限制其总文件大小：

    ```
    xfs_quota -x -c 'limit bsoft=768m bhard=1g john' /home/

    ```

1.  接下来，为另一个用户`joe`可以拥有的总*数量*文件创建用户配额：

    ```
    xfs_quota -x -c 'limit isoft=1000 ihard=5000 joe' /home/

    ```

1.  让我们为`devgrp`用户组中的每个人设置文件数量和大小限制（文件系统组`devgrp`必须存在）：

    ```
    xfs_quota -x -c 'limit -g bsoft=5g bhard=6g isoft=10000 ihard=50000 devgrp' /home

    ```

1.  最后，显示`home`卷的整个配额报告：

    ```
    xfs_quota -x -c 'report -bi -h' /home

    ```

### 启用项目（目录）配额

为了启用单个目录的磁盘配额而不是用户或组配额，我们必须将名为 `pquota` 的项目配额指令添加到包含该目录的卷中。由于我们将使用名为 `/srv/data` 的目录进行项目配额，我们需要将完整的底层 `/` 根分区置于配额控制之下。对于根分区，我们必须设置内核引导选项的配额标志：

1.  首先，在备份该文件后，以 root 身份打开以下文件：

    ```
    cp /etc/default/grub /etc/default/grub.BAK
    vi /etc/default/grub

    ```

1.  在行尾（在它之前添加一个空格字符）以 `GRUB_CMDLINE_LINUX=` 开头，在结束的双引号之前，添加 `rootflags=pquota` 指令，如下所示：

    ```
    GRUB_CMDLINE_LINUX="rd.lvm.lv=centos/root rd.lvm.lv=centos/swap crashkernel=auto rhgb quiet rootflags=pquota"

    ```

1.  保存并关闭文件，然后使用我们的新引导选项重建 `grub` 配置：

    ```
    grub2-mkconfig -o /boot/grub2/grub.cfg

    ```

1.  现在，在你的 `/etc/fstab` 中为根卷添加 `pquota` 标志：

    ```
    vi /etc/fstab

    ```

1.  将光标导航到包含根挂载点 / 的行，并将其移动到单词 `defaults`，然后添加以下文本，用逗号分隔：

    ```
    ,prjquota

    ```

1.  完整的行将类似于以下内容：

    ```
    /dev/mapper/myserver-root /         XFS    defaults,prjquota 0 0

    ```

1.  接下来，重启计算机以将更改应用到 `root` 卷：

    ```
    reboot

    ```

1.  重启后，确保 `root` 卷已启用项目配额，该配额在卷选项中定义为 `prjquota` 标志（否则，如果设置错误且不起作用，它将显示为 `noquota`）：

    ```
    cat /etc/mtab  | grep root

    ```

1.  接下来，让我们创建我们想要设置配额的目标文件夹：

    ```
    mkdir /srv/data

    ```

1.  我们需要添加一个项目名称和一个关联的新唯一 ID：

    ```
    echo "myProject:1400" >> /etc/projid

    ```

1.  现在，定义 `/srv/data` 将使用我们项目 ID 的配额规则：

    ```
    echo "1400:/srv/data" >> /etc/projects

    ```

1.  接下来，为 `root` 卷初始化 `project` 配额：

    ```
    xfs_quota -xc 'project -s myProject' /

    ```

1.  最后，应用以下规则来创建特定的目录限制：

    ```
    xfs_quota -x -c 'limit -p bsoft=1000m bhard=1200m myProject' /

    ```

1.  打印出我们为这个设备设定的配额规则：

    ```
    xfs_quota -x -c 'report -bi -h' /

    ```

## 它是如何工作的...

在本教程中，你学会了在用户、组或目录（项目）级别设置配额系统是多么容易。此外，你还了解到有两种基本方式来定义配额：要么对 *总文件大小*（称为块）施加限制，要么对 *文件数量*（称为 inode）设置限制。

那么，我们从这次经历中学到了什么？

我们从这个配方开始设置用户和组配额。正如你所见，通过在`/etc/fstab`文件中选择的分区添加相关的指令，可以轻松启用配额系统。因此，我们从这个文件开始，为 XFS 用户和组配额向我们的`/home`分区添加了特殊的配额关键词。为了应用这些更改，我们不得不使用`mount`命令重新挂载文件系统。由于配额系统已成功启动，我们使用`xfs_quota -x -c`命令行在我们的启用文件系统`/home`上设置了一些配额限制。`-x`启用专家模式，而`-c`允许我们在命令行上运行命令作为参数。当运行`xfs_quota`而不带`-c`选项时，你将进入一个交互式提示。首先，我们为用户`john`和`joe`设置了某些用户限制。我们通过定义以下参数及其数字来实现这一点：`bsoft`，`bhard`，`isoft`，`ihard`。如你所见，对于文件大小（**块**）和文件数量（**索引节点**）都有软限制和硬限制。块配额可以以典型的度量单位给出，如千字节（`k`），兆字节（`m`）和千兆字节（`g`），而索引节点是一个数字。软限制是一个阈值，当超过时，会在命令行上打印出警告消息，而硬限制将阻止用户在配额保护下的文件系统中添加更多数据或文件。之后，我们设置了一个基于组的配额。如果你使用`-g`标志，限制将为一个组而不是用户定义。根据用户应被允许拥有的文件数量或总文件大小，将用户分成不同的组，使用组规则可能非常有帮助。最后，我们为所有当前配额限制生成了一个报告。我们使用的命令是`'report -bi -h'`，它为已使用的文件空间（`-b`表示块）和总文件数量（`-i`表示索引节点）生成报告。`-h`指定我们希望输出以兆字节或千兆字节为单位，便于人类阅读。

为了测试配额是否有效，让我们为用户`jack`创建以下块和索引节点配额：

```
xfs_quota -x -c 'limit bhard=20m jack' /home/
xfs_quota -x -c 'limit ihard=1000 jack' /home/

```

以用户`jack`的身份登录（`su - jack`）并运行以下命令：

```
dd if=/dev/urandom of=~/test.dd bs=1M count=21

```

通过此命令，用户`john`将尝试创建一个 21 兆字节大小的文件，但在开始写入第二十兆字节时，将出现以下错误消息：

```
dd: error writing '/home/jack/test.dd': Disk quota exceeded

```

现在，删除`~/test.dd`文件，以便我们可以开始另一个测试。如果你超过了文件数量限制，同样的情况也会发生。通过尝试创建 2000 个多文件来测试以下配额限制，而配额限制为 1000；通过添加大量新文件来实现这一点：`for i in {1..2000}; do touch ~/test$i.txt; done`。这将导致以下错误消息：

```
touch: cannot touch '/home/jack/test1001.txt': Disk quota exceeded

```

要暂时关闭特定文件系统的用户和组配额检查，可以以`root`用户身份运行`xfs_quota -x -c 'off -u -g' /home/`（`-u`代表用户，`-g`代表组）。这只是一时的；要重新启用它，需要重新挂载感兴趣的文件系统，即`umount /home;mount -a`。要删除特定的配额规则，只需将其限制设置为零，例如：

```
xfs_quota -x -c 'limit bhard=0 john' /home

```

接下来，我们在*目录*级别而不是用户/组级别设置配额。这是 XFS 文件系统独有的功能；所有其他文件系统只能在磁盘或分区级别设置配额。如果您不想为特权用户或组设置配额限制，则能够控制目录层次结构的磁盘使用量非常有用。要激活目录配额，我们首先必须将其作为内核引导选项启用，因为默认情况下，根卷被标记为`noquota`。此外，我们在`/etc/fstab`中为根分区添加了`prjquota`指令以使其生效。如果您想了解更多关于内核引导选项的信息，请阅读第一章中的引导加载程序配方，*安装 CentOS*。要为根分区设置文件系统标志，我们需要重新启动系统。完成此操作后，我们通过查看`mtab`文件确保已成功设置引导选项，该文件列出了所有当前挂载的文件系统。接下来，我们在`/etc/projid`文件中设置了一个具有关联唯一项目 ID（我们随机选择`1400`）的项目名称。在下一步中，我们将此新项目 ID（`1400`）应用于`/etc/projects`文件中的目录`/srv/data`。该系统允许将特定的项目配额规则应用于许多不同的目录。之后，我们使用`xfs_quota`命令的`project`选项为根分区初始化项目配额，并为该项目名称创建了一个`limit`配额规则。在`/etc/projects`文件中定义的与相应项目 ID 对应的目录都会受到此规则的影响。这种类型的系统可用于精细的多文件夹配额规则。对于每个目录，您可以设置一个新的项目名称或重用特定的名称，使该系统非常灵活。

在本例中，我们为项目名称`myProject`设置了 1200 兆字节的块大小硬限制。要测试此配额，请输入以下内容：

```
dd if=/dev/zero of=/srv/data/dd.img bs=1M count=1201

```

使用以下命令行错误消息，应该可以在写入 1200 兆字节后准确停止`dd`：

```
dd: error writing '/srv/data/dd.img': No space left on device

```

## 还有更多...

顾名思义，本例中所示的`xfs_quota`程序仅适用于 XFS 文件系统。如果您想为其他文件系统（如 ext4 或 btrfs）在用户或组级别使用磁盘配额，则必须安装`quota`软件包（`yum install quota`）。设置配额的方式与本例中所示的步骤类似；请阅读手册`man quota`以开始使用。

# 维护文件系统

在本教程中，我们将学习如何检查和可选地修复 CentOS 7 文件系统的完整性。文件系统不一致是罕见的事件，文件系统检查通常在启动时自动运行。但是，系统管理员也应该知道如何手动运行这些测试，如果他们认为文件系统存在问题。

## 准备工作

要完成本教程，你需要一个具有 root 权限的 CentOS 7 操作系统的正常安装。我们将使用虚拟块设备而不是真实磁盘设备，因为我们*不能*在*已挂载*的磁盘上应用任何文件系统检查。因此，你应该已经应用了*格式化和挂载文件系统*教程，并创建了一个 1GB 的虚拟块设备，有两个分区，每个分区大小为总大小的一半：首先是一个带有 XFS 的分区，然后是另一个带有 ext4 文件系统的分区。在本例中，我们将使用名为`/dev/loop0`的虚拟块设备。

如前所述，这些可以很容易地替换为真实的磁盘名称。

## 如何操作...

1.  首先，以`root`身份登录，并显示当前连接到系统的块设备信息：

    ```
    lsblk -io NAME,TYPE,SIZE,MOUNTPOINT,FSTYPE,MODEL

    ```

1.  在这里，你应该看到`loop0`设备上有两个分区：`/dev/loop0p1`和`/dev/loop0p2`。如果你看到它们当前被挂载到系统上，请现在卸载它们：

    ```
    umount /dev/loop0p1
    umount /dev/loop0p2

    ```

1.  现在，让我们检查示例中的 loop0p1（适当更改）的 XFS 文件系统：

    ```
    xfs_repair -n /dev/loop0p1

    ```

1.  对于磁盘上的第二个 ext4 分区，我们将使用以下行：

    ```
    fsck -f /dev/loop0p2

    ```

## 工作原理...

在本教程中，我们学习了在 XFS 或 ext4 文件系统上运行文件系统检查是多么简单。你应该学到的最重要的一课是，在运行任何文件系统检查之前，你总是必须*卸载*你的磁盘分区！

那么，我们从这次经历中学到了什么？

由于我们不能在任何已挂载的设备上运行文件系统检查，如果你想检查系统的磁盘和分区，通常你必须在*救援*模式下运行这些检查，其中你的文件系统未挂载（例如，你不能卸载根分区来检查，因为它一直需要由系统使用，而对于单独的 home 分区，这是可能的）。

对于 XFS 文件系统，我们使用`xfs_repair`工具，对于其他所有文件系统，我们将使用带有`-f`参数（强制）的`fsck`程序来检查我们的文件系统。

重要的是要注意，我们总是需要运行`fsck`而不是特定的`fsck.<文件系统类型>`（如`fsck.ext4`，`fsck.btrfs`），因为它会自动检测正确的工具。这是必要的，因为如果你在错误的文件系统上运行错误的特定`fsck.<文件系统类型>`工具（比如在 btrfs 文件系统上运行`fsck.ext4`），它可能会完全破坏它！

## 还有更多...

到目前为止，我们只向你展示了如何使用`xfs_repair`和`fsck`*检查*文件系统。如果在 XFS 文件系统的“检查”运行期间出现错误，请在不使用`-n`选项的情况下运行`xfs_repair`——例如，使用`xfs_repair /dev/loop0p1`。在非 XFS 分区（如 ext4）上，你将使用`fsck`的`-a`选项（`a`代表自动修复）——例如，`fsck -a /dev/loop0p2`。对于`fsck`，如果你有很多错误，最好也使用`-y`，这样你就不必确认每个错误修复。

现在，让我们模拟如果我们使用虚拟块设备获得了一个损坏的 XFS 文件系统会发生什么（*千万不要*在任何真实磁盘分区上这样做！）：

1.  首先，将`/dev/loop0p1`分区挂载到你的根文件系统上：

    ```
    mkdir /media/vbd-1
    mount -t xfs /dev/loop0p1  /media/vbd-1

    ```

1.  接下来，在这个挂载的文件系统上创建大量文件——例如，`2000`个文件：

    ```
    for i in {1..2000}; do dd if=/dev/urandom bs=16 count=1 of=/media/vbd-1/file$i; done

    ```

1.  现在，卸载设备并使用`dd`破坏文件系统：

    ```
    umount /dev/loop0p1
    dd bs=512 count=10 seek=100 if=/dev/urandom of=/dev/loop0p1

    ```

1.  现在，运行文件系统检查：

    ```
    xfs_repair -n /dev/loop0p1

    ```

1.  这很可能会向你显示一份损坏文件的列表；为了修复它，请使用以下行：

    ```
    xfs_repair /dev/loop0p1

    ```

你还可以在你的 ext4 虚拟块设备上模拟文件系统损坏，然后使用`fsck -ay /dev/loop0p2`修复它。

# 扩展文件系统的容量

CentOS 7 使用**逻辑卷管理器**（**LVM**）来组织你的分区的结构和可用容量。它是一个非常动态和灵活的系统，可以随着时间的推移进行扩展或重新排列，并且在当今最苛刻和不断变化的环境中是必不可少的。目前，到处都可以听到大数据或云计算这样的流行词。由于不断产生大量数据，存储需求和磁盘空间必须以同样的稳定速度增长，。在这个食谱中，你将学习如何使用 LVM 系统，以及如何扩展你的物理驱动器，以及如何缩小和扩展你的文件系统的容量。

## 准备就绪

要完成这个食谱，你需要一个安装了 CentOS 7 操作系统并具有 root 权限的工作环境。我们将使用虚拟块设备而不是真实磁盘设备，从头开始教你如何设置 LVM，然后如何使用它。请阅读*创建虚拟块设备*食谱，并创建三个 1GB 的虚拟块设备，使用 GPT 分区表，在本例中将被标记为`/dev/loop0`、`/dev/loop1`和`/dev/loop2`。

再次，如果你准备好了，可以自由使用真实磁盘设备。

## 如何做到这一点...

首先，我们将开始创建一个类似于标准 CentOS 7 LVM 结构的 LVM 测试环境，该结构在每个服务器系统的安装过程中设置：

1.  首先，让我们以`root`身份登录并显示有关我们的虚拟块设备的信息：

    ```
    lsblk -io NAME,SIZE

    ```

1.  接下来，在每个三个虚拟块设备上创建跨越整个磁盘的新分区（不带文件系统标签）：

    ```
    parted -a optimal /dev/loop0 mkpart primary  2048KiB 100%
    parted -a optimal /dev/loop1 mkpart primary  2048KiB 100%
    parted -a optimal /dev/loop2 mkpart primary  2048KiB 100%

    ```

1.  现在，让我们在每个循环设备上创建 LVM*物理卷*（输入`yes`以移除`gpt`标签）：

    ```
    pvcreate /dev/loop0p1
    pvcreate /dev/loop1p1
    pvcreate /dev/loop2p1

    ```

1.  接下来，显示有关我们的物理卷的信息：

    ```
    pvdisplay

    ```

1.  接下来，我们将在第一个物理卷上创建一个新的 LVM 卷组：

    ```
    vgcreate myVG1 /dev/loop0p1

    ```

1.  现在，显示有关创建的组的信息：

    ```
    vgdisplay myVG1

    ```

1.  之后，让我们在我们的第一个卷组上创建一些逻辑卷，这些逻辑卷将被视为我们 Linux 系统中的虚拟分区：

    ```
    lvcreate -L 10m  -n swap myVG1
    lvcreate -L 100m -n home myVG1
    lvcreate -L 400m -n root myVG1

    ```

1.  接下来，显示有关逻辑卷的信息：

    ```
    lvdisplay myVG1

    ```

1.  现在，显示我们的底层卷组还剩下多少可用空间，如果你想扩展一些逻辑卷，这将变得很重要（查看输出中的`Free PE / Size`部分）：

    ```
    vgdisplay myVG1

    ```

1.  之后，让我们在那些新的逻辑卷上创建文件系统：

    ```
    mkswap /dev/myVG1/swap
    mkfs.xfs /dev/myVG1/home
    mkfs.xfs /dev/myVG1/root

    ```

1.  现在，在我们创建了测试 LVM 系统（它与真实的 CentOS LVM 标准布局非常相似，但尺寸较小）之后，让我们开始使用它。

1.  首先，让我们将`root`分区的大小从当前的`400`兆字节(`M`)缩小`200`兆字节，然后，让我们将`home`分区的大小增加`500`兆字节（确认可能的数据丢失）：

    ```
    lvresize -L -200m /dev/myVG1/root
    lvresize -L +500m /dev/myVG1/home

    ```

1.  再次使用`vgdisplay myVG1`来查看运行前面的命令后卷组的可用空间如何变化（查看`Free PE / Size`）。

1.  现在，让我们扩展增长，逻辑卷上的 XFS 文件系统：

    ```
    mkdir /media/home-test;mount /dev/myVG1/home /media/home-test
    xfs_growfs /dev/myVG1/home

    ```

    ### 注意

    非常重要的一点是，不要使用`resize2fs`来扩展 XFS 文件系统，因为它们不兼容，可能会导致文件系统损坏。

1.  现在，假设过了一段时间你的数据再次增长，你需要将 home 分区扩展到 1.5 千兆字节(`G`)，但你的底层卷组只剩下 184.00 MiB。首先，我们需要将本菜谱开始时准备的两个物理卷添加到我们的卷组中：

    ```
    vgextend myVG1 /dev/loop1p1 /dev/loop2p1
    vgdisplay myVG1

    ```

1.  之后，我们的卷组中有足够的可用空间（查看`Free PE / Size`）来扩展我们的 home 逻辑卷（卷必须保持挂载状态）：

    ```
    lvresize -L +1500m /dev/myVG1/home
    xfs_growfs /dev/myVG1/home

    ```

## 它是如何工作的...

在本菜谱中，我们向您展示了如何使用 LVM 处理 XFS 分区。它是为了动态管理多个硬盘上的磁盘空间而开发的。您可以轻松地将多个物理硬盘合并在一起，使它们对系统来说就像一个单一的虚拟硬盘。这使得它比使用传统的静态分区更加灵活和可扩展。传统的分区受限于它们所在的硬盘总容量，不能超过这个容量，而且它们的静态分区布局不容易改变。此外，我们还介绍了一些重要的 LVM 技术术语，它们为硬盘提供了不同的抽象层，本节将解释这些概念背后的内容：**物理卷**（**pv**）、**卷组**（**vg**）和**逻辑卷**（**lv**）。

那么，我们从这次经历中学到了什么？

我们从这个菜谱开始，创建了三个每个 1 千兆字节（`G`）的虚拟块设备，然后在每个设备上创建了一个跨越整个设备的分区。之后，我们使用`pvcreate`命令将这些单分区设备定义为物理卷（pv）。pv 是 LVM 术语，定义了 LVM 世界中的存储单元。它必须定义在分区、全驱动器或循环设备上。pv 只是对周围分区中所有可用空间的抽象，以便我们可以基于 LVM 进行工作。接下来，我们使用`vgcreate`命令创建了一个卷组（vg），在这里我们还必须定义一个我们选择的卷组名称，并将第一个 pv 作为基本存储卷放入其中。如你所见，一个 vg 至少包含一个 pv（我们稍后会添加更多 pv）。向 vg 添加或从 vg 删除 pv 是整个 LVM 系统可扩展性概念的核心。pv 不必都是相同的大小，并且可以通过添加数十个新物理驱动器（全部定义为 pv）来扩展 vg。你的系统上可以有多个 vg，并且可以通过你给它们的唯一名称来识别它们。因此，总之，要扩展 vg 的空间，你必须从物理驱动器创建 pv，然后你可以添加它们。

最终，我们在我们的卷组（vg）上创建了逻辑卷（lv），这些逻辑卷在卷组内部可以像真实的物理分区一样被看到和使用。在这里，我们使用`lvcreate`命令创建了三个 lv，通过这个命令我们需要定义我们想要放置目标 lv 的 vg 的名称（记住，你的系统上可以有多个 vg），以及卷的大小，以及作为最后一个参数的名称。你可以将多个 lv 添加到一个 vg 中，并且不需要使用 vg 底层可用空间中的全部分配空间。你可以非常灵活地使用它。最好的部分是，你关于卷的大小和布局的决定不必永远固定；你可以在任何时候更改它们。这是一个非常动态的系统，可以扩展和缩小，删除和创建，而不需要事先卸载卷。但是你必须记住，所有 lv 都绑定到一个 vg，没有 vg 就不可能创建它们，也不能超出其空间边界。如果你需要将 lv 的空间扩展到基础 vg 的边界之外，你必须扩展 vg，如本菜谱所示。

### 注意

你可能已经注意到，对于每个 LVM 术语，都有一个“显示”和“创建”命令，所以很容易记住：`pvdisplay`，`vgdisplay`，`lvdisplay`，`pvcreate`，`vgcreate`，`lvcreate`。

在成功创建了逻辑卷之后，您可以像处理系统上的其他块设备分区一样处理它们。唯一的区别是它们位于特殊的设备文件夹中：`/dev/<vg name>/<lv name>`或`/dev/mapper/<vg name>/<lv name>`。例如，在本示例中创建的家卷的名称为`/dev/myVG1/home`。最后，为了将它们用作正常的挂载点，我们在它们上创建了一些测试文件系统。

在本食谱的第二部分中，我们向您展示了如何扩展我们的卷组以及如何缩小和扩展我们的逻辑卷测试系统。

我们首先使用`vgdisplay myVG1`命令来显示卷组上当前可用的空间。在命令输出中，我们看到我们的当前卷组总共有`996M`（`VG Size`），我们的逻辑卷（`swap`，`home`，`root`）的已分配大小为`512M`（`Alloc PE / Size`），空闲大小为`484M`（`Free PE /Size`）。接下来，我们使用`lvresize`命令来缩小和扩展逻辑卷的根和家。`-L`参数设置卷的新大小，使用`+`或`-`符号，值将添加到或从逻辑卷的实际大小中减去。如果没有它，该值将被视为绝对值。请记住，我们只能增加家分区，因为当前卷布局没有占用卷组的总空间。调整大小后，如果我们再次使用`vgdisplay`命令，我们会看到我们现在在卷组中占用了更多的空间；其空闲大小已减少到`184M`。由于我们将`home`卷从`100M`扩展到`500M`，因此我们需要记住也要扩展其 XFS 文件系统，因为扩展卷不会自动扩展其文件系统。因此，当前卷的`400M`未分配，没有任何文件系统信息。我们使用了`xfs_growfs`命令，该命令将不定义限制参数，使用完整的未分配区域用于 XFS 文件系统。如果您想调整任何其他文件系统类型的大小，例如 ext4，则可以使用`resize2fs`命令代替。

最后，我们想将家卷扩展`1.5G`，但我们只有`184M`剩余的空间来扩展。这就是 LVM 真正*闪耀*的地方，因为我们可以简单地向其中添加更多的物理卷（在现实世界中，您只需在服务器中安装新的硬盘并将其用作 pvs）。我们向您展示了如何使用`vgextend`命令将两个 1G 大小的 pvs 添加到卷组中来*扩展*卷组的容量。之后，我们使用`vgdisplay`查看我们的卷组现在已经增长了 3G 的总大小，所以最后我们可以扩展我们的家逻辑卷，因为它现在可以适合它。作为最后一步，我们再次扩展了 XFS 文件系统，以填充整个 2G 的家卷大小。

请始终牢记，如果你在多个物理硬盘上使用 vg，你的数据将会在这些硬盘之间分布。LVM 并非 RAID 系统，不具备冗余性，因此如果一个硬盘损坏，你的整个 vg 也会随之失效，数据将丢失！为了解决这个问题，一个建议的解决方案是在硬盘上使用物理 RAID 系统，并在其上创建 LVM。
